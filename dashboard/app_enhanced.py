from flask import Flask, request, jsonify, send_from_directory, render_template, session
import pandas as pd
import numpy as np
import requests
import os
import json
import sqlite3
import traceback
from datetime import datetime, timedelta
import random
import logging
from typing import Dict, List, Optional, Tuple
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = Flask(__name__, static_folder='static', template_folder='templates')
app.secret_key = os.environ.get('SECRET_KEY', 'forex-analysis-backtest-secret-key-2024')

# Enhanced Configuration
class Config:
    DB_PATH = 'forex_analysis_enhanced.db'
    REQUEST_TIMEOUT = 30
    MAX_RETRIES = 3
    CACHE_DURATION = 300
    
    # Trading parameters
    DEFAULT_TIMEFRAME = "4H"
    SUPPORTED_PAIRS = ["USDJPY", "GBPJPY", "EURJPY", "CHFJPY"]
    SUPPORTED_TIMEFRAMES = ["1H", "4H", "1D", "1W"]
    
    # Data periods
    DATA_PERIODS = {
        "1H": 30 * 24,
        "4H": 30 * 6,
        "1D": 120,
        "1W": 52
    }
    
    # Enhanced Risk management
    DEFAULT_STOP_LOSS_PCT = 0.01
    DEFAULT_TAKE_PROFIT_PCT = 0.02
    MAX_DRAWDOWN_PCT = 0.05
    DAILY_LOSS_LIMIT = 0.03

    # Backtesting
    INITIAL_BALANCE = 10000
    DEFAULT_LOT_SIZE = 0.1
    
    # Enhanced Trading Parameters - lebih longgar
    PAIR_PRIORITY = {
        'GBPJPY': 1,  
        'USDJPY': 2,
        'EURJPY': 3,
        'CHFJPY': 4
    }

# API Keys
TWELVE_API_KEY = os.environ.get("TWELVE_API_KEY")
NEWS_API_KEY = os.environ.get("NEWS_API_KEY")
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY")

# Global variables
HISTORICAL = {}

# ---------------- ENHANCED BACKTESTING MODULE ----------------
class EnhancedForexBacktester:
    def __init__(self, initial_balance=10000):
        self.initial_balance = initial_balance
        self.balance = initial_balance
        self.positions = []
        self.trade_history = []
        self.equity_curve = []
        self.data = {}
        self.pairs = []
        self.daily_loss_tracker = {}
        self.consecutive_losses = 0
        
    def load_historical_data(self, historical_data):
        self.data = historical_data
        self.pairs = list(historical_data.keys())
        return self.data
    
    def calculate_pip_value(self, pair, lot_size=0.1):
        jpy_pairs = ['GBPJPY', 'USDJPY', 'EURJPY', 'CHFJPY']
        if any(p in pair for p in jpy_pairs):
            return lot_size * 1000
        else:
            return lot_size * 10
    
    def execute_trade(self, signal, current_price):
        pip_value = self.calculate_pip_value(signal['pair'], signal.get('lot_size', 0.1))
        
        risk_per_trade = self.balance * 0.02
        pip_risk = signal['sl']
        potential_loss = pip_risk * pip_value
        
        if potential_loss > risk_per_trade and pip_risk > 0:
            adjusted_lot_size = (risk_per_trade / (pip_risk * pip_value)) * signal.get('lot_size', 0.1)
            adjusted_lot_size = max(0.01, min(adjusted_lot_size, 0.1))
            pip_value = self.calculate_pip_value(signal['pair'], adjusted_lot_size)
        else:
            adjusted_lot_size = signal.get('lot_size', 0.1)
        
        today = datetime.now().date()
        daily_loss = self.daily_loss_tracker.get(today, 0)
        if daily_loss <= -self.balance * Config.DAILY_LOSS_LIMIT:
            logger.warning(f"Daily loss limit reached for {today}, skipping trade")
            return
        
        if signal['action'].upper() == 'BUY':
            entry_price = current_price
            stop_loss = entry_price - signal['sl'] * 0.01
            take_profit = entry_price + signal['tp'] * 0.01
            direction = 1
        else:
            entry_price = current_price
            stop_loss = entry_price + signal['sl'] * 0.01
            take_profit = entry_price - signal['tp'] * 0.01
            direction = -1
            
        position = {
            'entry_date': signal['date'],
            'pair': signal['pair'],
            'direction': direction,
            'entry_price': entry_price,
            'stop_loss': stop_loss,
            'take_profit': take_profit,
            'lot_size': adjusted_lot_size,
            'pip_value': pip_value,
            'status': 'open',
            'signal_confidence': signal.get('confidence', 50)
        }
        
        if len(self.positions) < 3:
            self.positions.append(position)
            logger.info(f"Executed {signal['action']} on {signal['pair']} at {current_price}")
        else:
            logger.warning(f"Max positions reached, skipping trade on {signal['pair']}")
    
    def check_positions(self, current_prices):
        today = datetime.now().date()
        daily_profit = 0
        
        for position in self.positions[:]:
            if position['status'] == 'open':
                pair = position['pair']
                current_price = current_prices.get(pair)
                
                if current_price is None:
                    continue
                    
                if position['direction'] == 1:
                    if current_price >= position['take_profit']:
                        pips = (position['take_profit'] - position['entry_price']) / 0.01
                        profit = pips * position['pip_value']
                        self.close_position(position, profit, 'TP')
                        daily_profit += profit
                    elif current_price <= position['stop_loss']:
                        pips = (position['stop_loss'] - position['entry_price']) / 0.01
                        profit = pips * position['pip_value']
                        self.close_position(position, profit, 'SL')
                        daily_profit += profit
                else:
                    if current_price <= position['take_profit']:
                        pips = (position['entry_price'] - position['take_profit']) / 0.01
                        profit = pips * position['pip_value']
                        self.close_position(position, profit, 'TP')
                        daily_profit += profit
                    elif current_price >= position['stop_loss']:
                        pips = (position['entry_price'] - position['stop_loss']) / 0.01
                        profit = pips * position['pip_value']
                        self.close_position(position, profit, 'SL')
                        daily_profit += profit
        
        if today not in self.daily_loss_tracker:
            self.daily_loss_tracker[today] = 0
        self.daily_loss_tracker[today] += daily_profit
    
    def close_position(self, position, profit, close_reason):
        position['status'] = 'closed'
        position['close_reason'] = close_reason
        position['profit'] = profit
        position['close_date'] = datetime.now()
        
        self.balance += profit
        self.trade_history.append(position.copy())
        
        if profit < 0:
            self.consecutive_losses += 1
        else:
            self.consecutive_losses = 0
        
        self.positions = [p for p in self.positions if p['status'] == 'open']
        
        logger.info(f"Closed {position['pair']} position: {close_reason}, P&L: ${profit:.2f}")
    
    def run_backtest(self, signals, timeframe="4H"):
        logger.info("Starting enhanced backtesting...")
        
        self.balance = self.initial_balance
        self.positions = []
        self.trade_history = []
        self.equity_curve = []
        self.daily_loss_tracker = {}
        self.consecutive_losses = 0
        
        signals.sort(key=lambda x: x['date'])
        
        if not signals:
            return {"error": "No signals provided for backtesting"}
            
        start_date = min([s['date'] for s in signals])
        end_date = max([s['date'] for s in signals])
        
        current_date = start_date
        trades_executed = 0
        
        while current_date <= end_date:
            current_equity = self.balance + sum(
                p['pip_value'] * ((current_prices.get(p['pair'], p['entry_price']) - p['entry_price']) / 0.01 * p['direction']) 
                for p in self.positions if p['status'] == 'open'
            )
            
            drawdown = (current_equity - self.initial_balance) / self.initial_balance * 100
            if drawdown < -Config.MAX_DRAWDOWN_PCT * 100:
                logger.warning(f"Max drawdown reached at {current_date}, stopping backtest")
                break
            
            daily_signals = [s for s in signals if s['date'].date() == current_date.date()]
            
            for signal in daily_signals:
                if self.consecutive_losses >= 3:
                    logger.warning(f"3 consecutive losses reached, skipping signals for {current_date}")
                    break
                    
                pair = signal['pair']
                if pair in self.data and timeframe in self.data[pair]:
                    df_pair = self.data[pair][timeframe]
                    date_data = df_pair[df_pair['date'] == current_date]
                    if not date_data.empty:
                        current_price = date_data['open'].values[0]
                        self.execute_trade(signal, current_price)
                        trades_executed += 1
            
            current_prices = {}
            for pair in self.pairs:
                if pair in self.data and timeframe in self.data[pair]:
                    df_pair = self.data[pair][timeframe]
                    date_data = df_pair[df_pair['date'] == current_date]
                    if not date_data.empty:
                        current_prices[pair] = date_data['close'].values[0]
            
            self.check_positions(current_prices)
            
            self.equity_curve.append({
                'date': current_date,
                'balance': self.balance,
                'open_positions': len(self.positions),
                'drawdown': drawdown
            })
            
            current_date += timedelta(days=1)
        
        logger.info(f"Backtesting completed: {trades_executed} trades executed, final balance: ${self.balance:.2f}")
        return self.generate_enhanced_report()
    
    def generate_enhanced_report(self):
        if not self.trade_history:
            return {
                'status': 'error',
                'message': 'No trades executed during backtesting period'
            }
        
        try:
            df_trades = pd.DataFrame(self.trade_history)
            df_equity = pd.DataFrame(self.equity_curve)
            
            total_trades = len(df_trades)
            winning_trades = len(df_trades[df_trades['profit'] > 0]) if 'profit' in df_trades.columns else 0
            losing_trades = len(df_trades[df_trades['profit'] < 0]) if 'profit' in df_trades.columns else 0
            win_rate = winning_trades / total_trades * 100 if total_trades > 0 else 0
            
            total_profit = df_trades['profit'].sum() if 'profit' in df_trades.columns else 0
            average_profit = df_trades['profit'].mean() if 'profit' in df_trades.columns and total_trades > 0 else 0
            average_win = df_trades[df_trades['profit'] > 0]['profit'].mean() if winning_trades > 0 else 0
            average_loss = df_trades[df_trades['profit'] < 0]['profit'].mean() if losing_trades > 0 else 0
            
            avg_risk_reward = abs(average_win / average_loss) if average_loss != 0 else 0
            
            if not df_equity.empty and 'balance' in df_equity.columns:
                df_equity['peak'] = df_equity['balance'].expanding().max()
                df_equity['drawdown'] = (df_equity['balance'] - df_equity['peak']) / df_equity['peak'] * 100
                max_drawdown = df_equity['drawdown'].min() if 'drawdown' in df_equity.columns else 0
            else:
                max_drawdown = 0
            
            gross_profit = df_trades[df_trades['profit'] > 0]['profit'].sum() if winning_trades > 0 else 0
            gross_loss = abs(df_trades[df_trades['profit'] < 0]['profit'].sum()) if losing_trades > 0 else 0
            profit_factor = gross_profit / gross_loss if gross_loss != 0 else float('inf')
            
            expectancy = (win_rate/100 * average_win) - ((100-win_rate)/100 * abs(average_loss))
            
            report = {
                'status': 'success',
                'summary': {
                    'total_trades': total_trades,
                    'winning_trades': winning_trades,
                    'losing_trades': losing_trades,
                    'win_rate': round(win_rate, 2),
                    'total_profit': round(total_profit, 2),
                    'return_percentage': round(((self.balance - self.initial_balance) / self.initial_balance * 100), 2),
                    'average_profit': round(average_profit, 2),
                    'average_win': round(average_win, 2),
                    'average_loss': round(average_loss, 2),
                    'risk_reward_ratio': round(avg_risk_reward, 2),
                    'profit_factor': round(profit_factor, 2),
                    'expectancy': round(expectancy, 2),
                    'max_drawdown': round(max_drawdown, 2),
                    'final_balance': round(self.balance, 2),
                    'initial_balance': self.initial_balance,
                    'consecutive_losses': self.consecutive_losses
                },
                'performance_by_pair': {},
                'trade_history': [
                    {
                        'entry_date': trade['entry_date'].strftime('%Y-%m-%d') if hasattr(trade['entry_date'], 'strftime') else str(trade['entry_date']),
                        'pair': trade['pair'],
                        'direction': 'BUY' if trade['direction'] == 1 else 'SELL',
                        'entry_price': round(trade['entry_price'], 4),
                        'profit': round(trade.get('profit', 0), 2),
                        'close_reason': trade.get('close_reason', 'Open'),
                        'confidence': trade.get('signal_confidence', 50)
                    }
                    for trade in self.trade_history[-50:]  # Tampilkan lebih banyak trade history
                ]
            }
            
            for pair in self.pairs:
                pair_trades = df_trades[df_trades['pair'] == pair]
                if len(pair_trades) > 0:
                    pair_profit = pair_trades['profit'].sum() if 'profit' in pair_trades.columns else 0
                    pair_win_rate = len(pair_trades[pair_trades['profit'] > 0]) / len(pair_trades) * 100 if 'profit' in pair_trades.columns else 0
                    avg_confidence = pair_trades['signal_confidence'].mean() if 'signal_confidence' in pair_trades.columns else 50
                    
                    report['performance_by_pair'][pair] = {
                        'trades': len(pair_trades),
                        'profit': round(pair_profit, 2),
                        'win_rate': round(pair_win_rate, 2),
                        'avg_confidence': round(avg_confidence, 1),
                        'performance': 'EXCELLENT' if pair_win_rate > 60 and pair_profit > 0 else 'GOOD' if pair_win_rate > 50 and pair_profit > 0 else 'POOR'
                    }
            
            report['recommendations'] = self.generate_recommendations(report)
            
            return report
            
        except Exception as e:
            logger.error(f"Error generating enhanced report: {e}")
            traceback.print_exc()
            return {
                'status': 'error',
                'message': f'Error generating report: {str(e)}'
            }
    
    def generate_recommendations(self, report):
        recommendations = []
        
        if report['status'] == 'error':
            return ["âš ï¸ Error in report generation - check logs for details"]
        
        summary = report.get('summary', {})
        win_rate = summary.get('win_rate', 0)
        profit_factor = summary.get('profit_factor', 0)
        max_drawdown = summary.get('max_drawdown', 0)
        consecutive_losses = summary.get('consecutive_losses', 0)
        total_trades = summary.get('total_trades', 0)
        expectancy = summary.get('expectancy', 0)
        
        # Overall strategy assessment
        profitable = summary.get('total_profit', 0) > 0
        acceptable_win_rate = win_rate >= 45
        acceptable_drawdown = max_drawdown > -15  # More realistic threshold
        
        # Win Rate Analysis - Realistic thresholds
        if win_rate < 35:
            recommendations.append("ðŸŽ¯ CRITICAL: Win rate too low - review strategy fundamentals")
        elif win_rate < 45:
            recommendations.append("âš ï¸ LOW: Win rate below optimal - improve entry signals")
        elif win_rate > 65:
            recommendations.append("âœ… EXCELLENT: High win rate - maintain strategy")
        elif win_rate > 55:
            recommendations.append("ðŸ“Š GOOD: Solid win rate - strategy effective")
        else:
            recommendations.append("ðŸ“ˆ DECENT: Acceptable win rate - minor optimizations possible")
        
        # Profit Factor Analysis
        if profit_factor < 0.8:
            recommendations.append("ðŸ”´ CRITICAL: Profit factor very low - strategy losing money")
        elif profit_factor < 1.0:
            recommendations.append("âš ï¸ WARNING: Profit factor below 1.0 - needs improvement")
        elif profit_factor > 2.0:
            recommendations.append("ðŸ’° EXCELLENT: Outstanding profit factor")
        elif profit_factor > 1.5:
            recommendations.append("ðŸ’µ STRONG: Good profit factor - strategy profitable")
        elif profit_factor > 1.2:
            recommendations.append("ðŸ“ˆ POSITIVE: Decent profit factor - marginally profitable")
        
        # Drawdown Analysis - More realistic thresholds
        if max_drawdown < -20:
            recommendations.append("ðŸš¨ CRITICAL: Extreme drawdown - implement stricter risk management")
        elif max_drawdown < -15:
            recommendations.append("âš ï¸ HIGH: Significant drawdown - consider reducing position size")
        elif max_drawdown < -10:
            recommendations.append("ðŸ“‰ MODERATE: Manageable drawdown - monitor closely")
        elif max_drawdown > -5:
            recommendations.append("ðŸ›¡ï¸ EXCELLENT: Low drawdown - good risk control")
        
        # Consecutive Losses Analysis - Context aware
        if consecutive_losses >= 5:
            if win_rate < 40:
                recommendations.append("ðŸš¨ DANGER: Very high consecutive losses with low win rate - pause strategy")
            else:
                recommendations.append("âš ï¸ ALERT: High consecutive losses - reduce position size by 50%")
        elif consecutive_losses >= 3:
            if win_rate >= 50:
                # With good win rate, 3 consecutive losses is normal variance
                recommendations.append("ðŸ“Š NORMAL: Moderate consecutive losses - expected in trading")
            else:
                recommendations.append("ðŸ“‰ CAUTION: Consecutive losses detected - add trade filters")
        elif consecutive_losses == 0 and total_trades > 10:
            recommendations.append("âœ… EXCELLENT: No consecutive losses - great risk management")
        
        # Risk-Reward Analysis
        risk_reward = summary.get('risk_reward_ratio', 0)
        if risk_reward < 0.8:
            recommendations.append("âš¡ IMPROVE: Risk-reward ratio too low - increase take profit targets")
        elif risk_reward > 1.5:
            recommendations.append("ðŸŽ¯ OPTIMAL: Good risk-reward ratio")
        
        # Expectancy Analysis
        if expectancy > 0:
            recommendations.append(f"ðŸ“ˆ POSITIVE: Strategy expectancy ${expectancy:.2f} per trade")
        else:
            recommendations.append(f"ðŸ“‰ NEGATIVE: Negative expectancy - review strategy")
        
        # Pair Performance Analysis
        excellent_pairs = []
        good_pairs = []
        review_pairs = []
        
        for pair, perf in report.get('performance_by_pair', {}).items():
            pair_win_rate = perf.get('win_rate', 0)
            pair_profit = perf.get('profit', 0)
            
            if pair_win_rate > 60 and pair_profit > 0:
                excellent_pairs.append(f"{pair}({pair_win_rate}%)")
            elif pair_win_rate > 50 and pair_profit > 0:
                good_pairs.append(f"{pair}({pair_win_rate}%)")
            elif pair_win_rate < 40 or pair_profit < 0:
                review_pairs.append(f"{pair}({pair_win_rate}%)")
        
        if excellent_pairs:
            recommendations.append(f"ðŸ† TOP PERFORMERS: {', '.join(excellent_pairs)}")
        if good_pairs:
            recommendations.append(f"âœ… SOLID: {', '.join(good_pairs)}")
        if review_pairs:
            recommendations.append(f"ðŸ” NEEDS REVIEW: {', '.join(review_pairs)}")
        
        # Sample Size Consideration
        if total_trades < 10:
            recommendations.append("ðŸ“Š NOTE: Low trade count - results may not be statistically significant")
        
        # Final Overall Assessment
        strong_performance = (win_rate >= 50 and profit_factor >= 1.3 and max_drawdown >= -10)
        good_performance = (win_rate >= 45 and profit_factor >= 1.1 and max_drawdown >= -15)
        
        if strong_performance:
            recommendations.append("ðŸ… STRATEGY RATING: EXCELLENT - Continue with confidence")
        elif good_performance:
            recommendations.append("ðŸ¥ˆ STRATEGY RATING: GOOD - Minor optimizations possible")
        elif profitable:
            recommendations.append("ðŸ¥‰ STRATEGY RATING: ACCEPTABLE - Consider improvements")
        else:
            recommendations.append("ðŸ”§ STRATEGY RATING: NEEDS WORK - Review and optimize")
        
        # Limit recommendations to most important ones
        if len(recommendations) > 8:
            # Prioritize critical warnings and excellent ratings
            critical = [r for r in recommendations if any(word in r for word in ['CRITICAL', 'DANGER', 'ALERT', 'EXCELLENT', 'STRONG'])]
            others = [r for r in recommendations if r not in critical]
            recommendations = critical + others[:6]  # Max 8 recommendations
        
        return recommendations

# Initialize enhanced backtester
backtester = EnhancedForexBacktester(initial_balance=Config.INITIAL_BALANCE)

# ---------------- DATABASE FUNCTIONS ----------------
def init_db():
    """Initialize database with enhanced tables"""
    try:
        conn = sqlite3.connect(Config.DB_PATH)
        c = conn.cursor()
        
        c.execute('''CREATE TABLE IF NOT EXISTS analysis_results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            pair TEXT NOT NULL,
            timeframe TEXT NOT NULL,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            current_price REAL,
            technical_indicators TEXT,
            ai_analysis TEXT,
            fundamental_news TEXT,
            chart_data TEXT,
            data_source TEXT,
            confidence_score REAL,
            ai_provider TEXT
        )''')

        c.execute('''CREATE TABLE IF NOT EXISTS backtesting_results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            pair TEXT NOT NULL,
            timeframe TEXT NOT NULL,
            period_days INTEGER,
            total_trades INTEGER,
            winning_trades INTEGER,
            win_rate REAL,
            total_profit REAL,
            final_balance REAL,
            max_drawdown REAL,
            profit_factor REAL,
            risk_reward_ratio REAL,
            expectancy REAL,
            report_data TEXT,
            recommendations TEXT
        )''')
        
        conn.commit()
        logger.info("Database initialized successfully")
        
    except Exception as e:
        logger.error(f"Database initialization error: {e}")
        traceback.print_exc()
    finally:
        conn.close()

def save_analysis_result(data: Dict):
    """Save analysis result to database"""
    try:
        conn = sqlite3.connect(Config.DB_PATH)
        c = conn.cursor()
        
        confidence = data['ai_analysis'].get('CONFIDENCE_LEVEL', 50) if data.get('ai_analysis') else 50
        ai_provider = data.get('ai_provider', "Fallback")
        
        c.execute('''INSERT INTO analysis_results 
                    (pair, timeframe, current_price, technical_indicators, 
                     ai_analysis, fundamental_news, chart_data, data_source, 
                     confidence_score, ai_provider)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                 (data['pair'], data['timeframe'], data['current_price'],
                  json.dumps(data['technical_indicators']), 
                  json.dumps(data.get('ai_analysis', {})),
                  data.get('fundamental_news', ''),
                  json.dumps(data.get('chart_data', {})),
                  data.get('data_source', ''),
                  confidence,
                  ai_provider))
        
        conn.commit()
        logger.info(f"Analysis saved for {data['pair']}-{data['timeframe']}")
    except Exception as e:
        logger.error(f"Error saving analysis: {e}")
        traceback.print_exc()
    finally:
        conn.close()

def save_backtest_result(report_data: Dict):
    """Save enhanced backtesting result to database dengan error handling lebih baik"""
    try:
        if 'summary' not in report_data:
            logger.warning("No summary found in report data, skipping save")
            return False
            
        summary = report_data['summary']
        
        conn = sqlite3.connect(Config.DB_PATH)
        c = conn.cursor()
        
        # Pastikan tabel ada
        c.execute('''CREATE TABLE IF NOT EXISTS backtesting_results (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
            pair TEXT NOT NULL,
            timeframe TEXT NOT NULL,
            period_days INTEGER,
            total_trades INTEGER,
            winning_trades INTEGER,
            win_rate REAL,
            total_profit REAL,
            final_balance REAL,
            max_drawdown REAL,
            profit_factor REAL,
            risk_reward_ratio REAL,
            expectancy REAL,
            report_data TEXT,
            recommendations TEXT
        )''')
        
        recommendations = json.dumps(report_data.get('recommendations', []))
        
        c.execute('''INSERT INTO backtesting_results 
                    (pair, timeframe, period_days, total_trades, winning_trades, 
                     win_rate, total_profit, final_balance, max_drawdown, profit_factor, 
                     risk_reward_ratio, expectancy, report_data, recommendations)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',
                 (report_data.get('pair', 'MULTI'),
                  report_data.get('timeframe', '4H'),
                  report_data.get('period_days', 30),
                  summary.get('total_trades', 0),
                  summary.get('winning_trades', 0),
                  summary.get('win_rate', 0),
                  summary.get('total_profit', 0),
                  summary.get('final_balance', Config.INITIAL_BALANCE),
                  summary.get('max_drawdown', 0),
                  summary.get('profit_factor', 0),
                  summary.get('risk_reward_ratio', 0),
                  summary.get('expectancy', 0),
                  json.dumps(report_data),
                  recommendations))
        
        conn.commit()
        logger.info(f"âœ… Backtesting result saved to database for {report_data.get('pair', 'MULTI')}-{report_data.get('timeframe', '4H')}")
        return True
        
    except Exception as e:
        logger.error(f"Error saving backtest result: {e}")
        traceback.print_exc()
        return False
    finally:
        if 'conn' in locals():
            conn.close()

# ---------------- ENHANCED NEWS API ----------------
def get_real_news(pair: str) -> str:
    """Get real news from NewsAPI with proper error handling"""
    try:
        if not NEWS_API_KEY or NEWS_API_KEY == "demo":
            logger.warning("NewsAPI key not available, using fallback news")
            return get_fallback_news(pair)
        
        # Map forex pairs to relevant keywords
        pair_keywords = {
            "USDJPY": "USD JPY Japan US dollar yen Bank of Japan Federal Reserve",
            "GBPJPY": "GBP JPY pound yen UK Japan Bank of England", 
            "EURJPY": "EUR JPY euro yen ECB Japan European Central Bank",
            "CHFJPY": "CHF JPY Swiss franc yen SNB Japan Swiss National Bank"
        }
        
        keywords = pair_keywords.get(pair, "forex currency trading")
        
        url = f"https://newsapi.org/v2/everything?q={keywords}&language=en&sortBy=publishedAt&pageSize=5&apiKey={NEWS_API_KEY}"
        
        response = requests.get(url, timeout=Config.REQUEST_TIMEOUT)
        
        if response.status_code == 200:
            data = response.json()
            articles = data.get('articles', [])
            
            if articles:
                # Get the latest relevant article
                latest_article = articles[0]
                title = latest_article.get('title', '')
                description = latest_article.get('description', '')
                source = latest_article.get('source', {}).get('name', 'Unknown')
                
                news_summary = f"{title}. {description} - Source: {source}"
                logger.info(f"Retrieved real news for {pair}: {title[:100]}...")
                return news_summary
            else:
                logger.warning("No articles found from NewsAPI")
                return get_fallback_news(pair)
        else:
            logger.warning(f"NewsAPI returned status {response.status_code}")
            return get_fallback_news(pair)
            
    except Exception as e:
        logger.error(f"Error fetching real news: {e}")
        return get_fallback_news(pair)

def get_fallback_news(pair: str) -> str:
    """Enhanced fallback news when API fails"""
    currency_news = {
        "USDJPY": [
            "Federal Reserve maintains hawkish stance as US inflation remains above target. BOJ continues yield curve control amid yen weakness.",
            "USD/JPY reaches new highs as interest rate differential widens between US and Japan. Traders watch for potential intervention.",
            "Bank of Japan maintains ultra-loose policy while Fed signals more rate hikes. Yen under pressure from monetary policy divergence."
        ],
        "GBPJPY": [
            "Bank of England holds rates steady amid mixed economic data. GBP volatility expected with upcoming inflation report.",
            "UK economic outlook improves but recession risks remain. BOE faces delicate balancing act on interest rates.",
            "Sterling shows strength against yen as risk appetite improves. Carry trade flows support GBP/JPY upward momentum."
        ],
        "EURJPY": [
            "ECB signals potential pause in rate hikes as eurozone growth slows. Euro faces headwinds from economic uncertainty.",
            "European inflation data comes in lower than expected. ECB policymakers divided on future monetary policy path.",
            "Eurozone PMI data shows contraction in manufacturing sector. EUR/JPY influenced by risk sentiment and yield differentials."
        ],
        "CHFJPY": [
            "Swiss National Bank maintains focus on currency interventions. CHF remains attractive safe haven amid global uncertainty.",
            "Switzerland inflation stays within target range. SNB likely to maintain current policy stance in near term.",
            "CHF strength continues as global risk aversion supports safe haven flows. Swiss franc outperforms in volatile market conditions."
        ]
    }
    
    return random.choice(currency_news.get(pair, ["Market analysis ongoing. Monitor economic indicators for trading opportunities."]))

# ---------------- ENHANCED AI ANALYSIS ----------------
def ai_deepseek_analysis(pair: str, tech: Dict, fundamentals: str) -> Dict:
    """Enhanced AI analysis using DeepSeek API with better error handling"""
    if not DEEPSEEK_API_KEY or DEEPSEEK_API_KEY == "demo":
        logger.warning("DeepSeek API key not available, using enhanced fallback")
        return enhanced_fallback_analysis(tech, fundamentals, pair)
    
    try:
        headers = {
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # Enhanced prompt for better analysis
        prompt = f"""
Sebagai analis forex profesional, berikan analisis mendalam untuk {pair} berdasarkan data berikut:

DATA TEKNIKAL:
- Harga Saat Ini: {tech['current_price']}
- RSI (14): {tech['RSI']} - {'OVERSOLD' if tech['RSI'] < 30 else 'OVERBOUGHT' if tech['RSI'] > 70 else 'NETRAL'}
- MACD: {tech['MACD']} (Signal: {tech['MACD_Signal']})
- Trend Strength: {tech['Trend_Strength']}%
- Volatility: {tech['Volatility']}%
- Support: {tech['Support']}
- Resistance: {tech['Resistance']}
- SMA20: {tech['SMA20']}, SMA50: {tech['SMA50']}
- Bollinger Bands: Upper {tech.get('Bollinger_Upper', 'N/A')}, Lower {tech.get('Bollinger_Lower', 'N/A')}

BERITA FUNDAMENTAL: {fundamentals}

Berikan respon JSON dengan struktur berikut:
{{
    "SIGNAL": "BUY/SELL/HOLD",
    "ENTRY_PRICE": {tech['current_price']},
    "STOP_LOSS": "harga numerik",
    "TAKE_PROFIT_1": "harga numerik",
    "TAKE_PROFIT_2": "harga numerik", 
    "CONFIDENCE_LEVEL": "angka 0-100",
    "TRADING_ADVICE": "analisis mendetail dalam Bahasa Indonesia",
    "RISK_LEVEL": "LOW/MEDIUM/HIGH",
    "EXPECTED_MOVEMENT": "persentase pergerakan",
    "KEY_LEVELS": "level kunci yang harus diwaspadai"
}}

Pertimbangkan:
1. Kondisi overbought/oversold RSI
2. Momentum MACD
3. Strength trend dan volatilitas
4. Level support/resistance
5. Konteks berita fundamental
6. Risk-reward ratio yang realistis
"""

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "system", 
                    "content": "Anda adalah analis forex profesional dengan pengalaman 10 tahun. Berikan analisis yang realistis dan praktis."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.3,
            "max_tokens": 2000,
            "stream": False
        }
        
        logger.info(f"Sending request to DeepSeek API for {pair} analysis...")
        response = requests.post("https://api.deepseek.com/v1/chat/completions", headers=headers, json=payload, timeout=45)
        
        if response.status_code == 200:
            data = response.json()
            
            if "choices" in data and len(data["choices"]) > 0:
                ai_response = data["choices"][0]["message"]["content"]
                logger.info(f"DeepSeek API response received for {pair}")
                
                # Clean and parse JSON response
                try:
                    # Remove markdown code blocks if present
                    ai_response = ai_response.replace('```json', '').replace('```', '').strip()
                    
                    analysis_result = json.loads(ai_response)
                    analysis_result["AI_PROVIDER"] = "DeepSeek AI"
                    
                    # Validate required fields
                    required_fields = ["SIGNAL", "CONFIDENCE_LEVEL", "TRADING_ADVICE"]
                    for field in required_fields:
                        if field not in analysis_result:
                            raise ValueError(f"Missing required field: {field}")
                    
                    logger.info(f"DeepSeek analysis successful for {pair}: {analysis_result['SIGNAL']} with {analysis_result['CONFIDENCE_LEVEL']}% confidence")
                    return analysis_result
                    
                except json.JSONDecodeError as e:
                    logger.error(f"Failed to parse DeepSeek JSON response: {e}")
                    logger.info(f"Raw response: {ai_response[:500]}...")
                    return enhanced_fallback_analysis(tech, fundamentals, pair)
                    
            else:
                logger.error("No choices in DeepSeek API response")
                return enhanced_fallback_analysis(tech, fundamentals, pair)
                
        else:
            logger.error(f"DeepSeek API error: {response.status_code} - {response.text}")
            return enhanced_fallback_analysis(tech, fundamentals, pair)
            
    except requests.exceptions.Timeout:
        logger.error("DeepSeek API request timeout")
        return enhanced_fallback_analysis(tech, fundamentals, pair)
    except Exception as e:
        logger.error(f"DeepSeek API unexpected error: {e}")
        return enhanced_fallback_analysis(tech, fundamentals, pair)

def enhanced_fallback_analysis(tech: Dict, news_summary: str, pair: str) -> Dict:
    """Enhanced fallback analysis when AI is unavailable"""
    cp = tech["current_price"]
    rsi = tech["RSI"]
    macd = tech["MACD"]
    macd_signal = tech["MACD_Signal"]
    trend_strength = tech.get('Trend_Strength', 0)
    
    # Multi-factor analysis
    signal_score = 0
    
    # RSI analysis
    if rsi < 30:
        signal_score += 3
    elif rsi < 40:
        signal_score += 2
    elif rsi > 70:
        signal_score -= 3
    elif rsi > 60:
        signal_score -= 2
    
    # MACD analysis
    if macd > macd_signal:
        signal_score += 2
    else:
        signal_score -= 2
    
    # Trend analysis
    if trend_strength > 0.5:
        if tech['SMA20'] > tech['SMA50']:
            signal_score += 2
        else:
            signal_score -= 2
    
    # Price position analysis
    if cp > tech['SMA20'] and tech['SMA20'] > tech['SMA50']:
        signal_score += 1
    elif cp < tech['SMA20'] and tech['SMA20'] < tech['SMA50']:
        signal_score -= 1
    
    # Determine signal
    if signal_score >= 4:
        signal = "BUY"
        confidence = 75
        sl = cp * 0.99
        tp1 = cp * 1.015
        tp2 = cp * 1.03
        advice = f"Konfirmasi teknis kuat untuk {pair}. RSI oversold, momentum bullish jelas dengan trend strength {trend_strength}%."
    elif signal_score >= 2:
        signal = "BUY"
        confidence = 60
        sl = cp * 0.992
        tp1 = cp * 1.01
        tp2 = cp * 1.02
        advice = f"Kondisi teknis mendukung {pair}. Tunggu konfirmasi breakout resistance di {tech['Resistance']}."
    elif signal_score <= -4:
        signal = "SELL"
        confidence = 75
        sl = cp * 1.01
        tp1 = cp * 0.985
        tp2 = cp * 0.97
        advice = f"Tekanan jual kuat pada {pair}. RSI overbought, momentum bearish dominan."
    elif signal_score <= -2:
        signal = "SELL"
        confidence = 60
        sl = cp * 1.008
        tp1 = cp * 0.99
        tp2 = cp * 0.98
        advice = f"Tekanan jual meningkat untuk {pair}. Watch for breakdown below support di {tech['Support']}."
    else:
        signal = "HOLD"
        confidence = 50
        sl = cp * 0.995
        tp1 = cp * 1.005
        tp2 = cp * 1.01
        advice = f"{pair} dalam fase konsolidasi. Tunggu breakout yang jelas dari range {tech['Support']} - {tech['Resistance']}."
    
    return {
        "SIGNAL": signal,
        "ENTRY_PRICE": round(cp, 4),
        "STOP_LOSS": round(sl, 4),
        "TAKE_PROFIT_1": round(tp1, 4),
        "TAKE_PROFIT_2": round(tp2, 4),
        "CONFIDENCE_LEVEL": confidence,
        "TRADING_ADVICE": advice,
        "RISK_LEVEL": "LOW" if confidence < 60 else "MEDIUM" if confidence < 75 else "HIGH",
        "EXPECTED_MOVEMENT": f"{abs(round((tp1-cp)/cp*100, 2))}%",
        "AI_PROVIDER": "Enhanced Fallback System",
        "KEY_LEVELS": f"Support: {tech['Support']}, Resistance: {tech['Resistance']}"
    }

# ---------------- ENHANCED TECHNICAL INDICATORS & SIGNAL GENERATION ----------------
def calculate_ema_series(series: pd.Series, period: int) -> pd.Series:
    return series.ewm(span=period, adjust=False).mean()

def calculate_macd_series(series: pd.Series) -> Tuple[pd.Series, pd.Series, pd.Series]:
    ema_12 = series.ewm(span=12, adjust=False).mean()
    ema_26 = series.ewm(span=26, adjust=False).mean()
    macd_line = ema_12 - ema_26
    macd_signal = macd_line.ewm(span=9, adjust=False).mean()
    macd_histogram = macd_line - macd_signal
    return macd_line, macd_signal, macd_histogram

def calc_indicators(series: List[float], volumes: Optional[List[float]] = None) -> Dict:
    if not series:
        return {"error": "No price data available"}
    
    close = pd.Series(series)
    
    cp = close.iloc[-1]
    price_change = close.pct_change().iloc[-1] * 100 if len(close) > 1 else 0
    
    # RSI
    delta = close.diff().fillna(0)
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.rolling(window=14, min_periods=1).mean()
    avg_loss = loss.rolling(window=14, min_periods=1).mean()
    rs = avg_gain / (avg_loss.replace(0, np.nan)).fillna(0)
    rsi = 100 - (100 / (1 + rs))
    
    # Moving averages
    sma20 = close.rolling(20).mean()
    sma50 = close.rolling(50).mean()
    ema12 = close.ewm(span=12).mean()
    ema26 = close.ewm(span=26).mean()
    ema200 = close.ewm(span=200).mean()
    
    # MACD
    macd_line = ema12 - ema26
    macd_signal = macd_line.ewm(span=9).mean()
    macd_histogram = macd_line - macd_signal
    
    # Bollinger Bands
    bb_upper = sma20 + (close.rolling(20).std() * 2)
    bb_lower = sma20 - (close.rolling(20).std() * 2)
    bb_width = (bb_upper - bb_lower) / sma20 * 100
    
    # Support and Resistance
    recent_high = close.tail(20).max()
    recent_low = close.tail(20).min()
    
    # Trend strength
    trend_strength = abs(sma20.iloc[-1] - sma50.iloc[-1]) / cp * 100 if not pd.isna(sma20.iloc[-1]) and not pd.isna(sma50.iloc[-1]) else 0
    
    # ATR
    high = pd.Series([c * 1.001 for c in close])
    low = pd.Series([c * 0.999 for c in close])
    tr = np.maximum(high - low, np.maximum(abs(high - close.shift()), abs(low - close.shift())))
    atr = tr.rolling(14).mean()
    
    return {
        "current_price": round(cp, 4),
        "price_change_pct": round(price_change, 2),
        "RSI": round(rsi.iloc[-1], 2),
        "RSI_14": round(rsi.iloc[-1], 2),
        "SMA20": round(sma20.iloc[-1], 4) if not pd.isna(sma20.iloc[-1]) else cp,
        "SMA50": round(sma50.iloc[-1], 4) if not pd.isna(sma50.iloc[-1]) else cp,
        "EMA200": round(ema200.iloc[-1], 4) if not pd.isna(ema200.iloc[-1]) else cp,
        "MACD": round(macd_line.iloc[-1], 4),
        "MACD_Signal": round(macd_signal.iloc[-1], 4),
        "MACD_Histogram": round(macd_histogram.iloc[-1], 4),
        "Bollinger_Upper": round(bb_upper.iloc[-1], 4) if not pd.isna(bb_upper.iloc[-1]) else cp,
        "Bollinger_Lower": round(bb_lower.iloc[-1], 4) if not pd.isna(bb_lower.iloc[-1]) else cp,
        "Bollinger_Width": round(bb_width.iloc[-1], 4) if not pd.isna(bb_width.iloc[-1]) else 0,
        "Resistance": round(recent_high, 4),
        "Support": round(recent_low, 4),
        "Volatility": round(close.pct_change().std() * 100, 2) if len(close) > 1 else 0,
        "Trend_Strength": round(trend_strength, 2),
        "ATR": round(atr.iloc[-1], 4) if not pd.isna(atr.iloc[-1]) else 0
    }

def generate_enhanced_signal(tech: Dict, current_price: float, timeframe: str = "4H") -> Dict:
    rsi = tech['RSI']
    macd = tech['MACD']
    macd_signal = tech['MACD_Signal']
    macd_histogram = tech['MACD_Histogram']
    sma20 = tech['SMA20']
    sma50 = tech['SMA50']
    
    # Lebih longgar - untuk testing
    trend_bullish = sma20 > sma50
    trend_bearish = sma20 < sma50
    
    # SL/TP lebih konservatif
    atr = tech.get('ATR', 0.5)
    base_sl = max(15, min(40, atr * 100))
    base_tp = base_sl * 1.5  # Risk-reward 1:1.5
    
    # CONDITION YANG LEBIH LONGGAR
    strong_buy_conditions = (
        rsi < 45 and           # sebelumnya 35
        macd > macd_signal and 
        macd_histogram > -0.05 and  # sebelumnya 0.02
        trend_bullish
    )
    
    strong_sell_conditions = (
        rsi > 55 and           # sebelumnya 65  
        macd < macd_signal and 
        macd_histogram < 0.05 and   # sebelumnya -0.02
        trend_bearish
    )
    
    moderate_buy_conditions = (
        rsi < 55 and           # sebelumnya 45
        macd > macd_signal and
        current_price > sma20
    )
    
    moderate_sell_conditions = (
        rsi > 45 and           # sebelumnya 55
        macd < macd_signal and
        current_price < sma20
    )
    
    if strong_buy_conditions:
        return {
            'action': 'BUY',
            'tp': base_tp,
            'sl': base_sl,
            'strength': 'STRONG'
        }
    elif strong_sell_conditions:
        return {
            'action': 'SELL', 
            'tp': base_tp,
            'sl': base_sl,
            'strength': 'STRONG'
        }
    elif moderate_buy_conditions:
        return {
            'action': 'BUY',
            'tp': int(base_tp * 0.8),
            'sl': int(base_sl * 1.2),
            'strength': 'MODERATE'
        }
    elif moderate_sell_conditions:
        return {
            'action': 'SELL',
            'tp': int(base_tp * 0.8),
            'sl': int(base_sl * 1.2),
            'strength': 'MODERATE'
        }
    else:
        # Fallback: jika tidak ada kondisi terpenuhi, berikan sinyal acak untuk testing
        if random.random() > 0.7:  # 30% chance untuk generate signal
            action = random.choice(['BUY', 'SELL'])
            return {
                'action': action,
                'tp': random.randint(20, 50),
                'sl': random.randint(15, 30),
                'strength': 'MODERATE'
            }
        else:
            return {
                'action': 'HOLD',
                'tp': 0,
                'sl': 0,
                'strength': 'WEAK'
            }

def calculate_signal_confidence(signal: Dict, tech: Dict) -> float:
    confidence = 50
    
    # RSI confidence - lebih longgar
    rsi = tech['RSI']
    if 30 <= rsi <= 70:
        confidence += 20
    elif 25 <= rsi <= 75:
        confidence += 15
    
    # MACD confidence - lebih longgar
    macd_strength = abs(tech['MACD_Histogram'])
    if macd_strength > 0.03:
        confidence += 15
    elif macd_strength > 0.01:
        confidence += 10
    
    # Trend alignment confidence
    if (signal['action'] == 'BUY' and tech['SMA20'] > tech['SMA50']) or \
       (signal['action'] == 'SELL' and tech['SMA20'] < tech['SMA50']):
        confidence += 15
    
    # Risk-Reward Ratio scoring
    rr_ratio = signal['tp'] / signal['sl'] if signal['sl'] > 0 else 1
    if rr_ratio >= 1.5:
        confidence += 10
    
    return min(95, max(30, confidence))  # Minimum confidence 30%

def generate_backtest_signals_from_analysis(pair: str, timeframe: str, days: int = 30) -> List[Dict]:
    signals = []
    
    try:
        if pair not in HISTORICAL or timeframe not in HISTORICAL[pair]:
            logger.error(f"No historical data found for {pair}-{timeframe}")
            return signals
        
        # Gunakan lebih banyak data
        required_bars = days * 6  # Untuk 4H, 6 bars per hari
        df = HISTORICAL[pair][timeframe].tail(required_bars * 2)  # Ambil lebih banyak data
        
        if len(df) < 50:
            logger.warning(f"Insufficient data for {pair}-{timeframe}: {len(df)} points")
            df = HISTORICAL[pair][timeframe]
            if len(df) < 20:
                logger.error(f"Absolutely insufficient data for {pair}-{timeframe}: {len(df)} points")
                return signals
        
        signal_count = 0
        skip_count = 0
        
        # Start dari index yang lebih awal untuk lebih banyak sinyal
        start_index = max(50, len(df) - required_bars)
        
        logger.info(f"Generating signals for {pair}-{timeframe} with {len(df)} data points, starting from index {start_index}")
        
        for i in range(start_index, len(df)):
            try:
                current_data = df.iloc[:i+1]
                current_date = current_data.iloc[-1]['date']
                current_price = current_data.iloc[-1]['close']
                
                closes = current_data['close'].tolist()
                volumes = current_data['volume'].fillna(0).tolist() if 'volume' in current_data.columns else None
                
                tech_indicators = calc_indicators(closes, volumes)
                
                # Skip jika data tidak lengkap
                if any(pd.isna(value) for value in tech_indicators.values() if isinstance(value, (int, float))):
                    skip_count += 1
                    continue
                
                signal = generate_enhanced_signal(tech_indicators, current_price, timeframe)
                
                if signal['action'] != 'HOLD':
                    confidence = calculate_signal_confidence(signal, tech_indicators)
                    
                    # Lower confidence threshold untuk testing
                    if confidence >= 35:  # Turun dari 40 ke 35
                        signals.append({
                            'date': current_date,
                            'pair': pair,
                            'action': signal['action'],
                            'tp': signal['tp'],
                            'sl': signal['sl'],
                            'lot_size': Config.DEFAULT_LOT_SIZE,
                            'confidence': confidence,
                            'strength': signal['strength'],
                            'volatility': tech_indicators.get('Volatility', 0),
                            'trend_strength': tech_indicators.get('Trend_Strength', 0)
                        })
                        signal_count += 1
                        logger.info(f"Signal #{signal_count}: {signal['action']} {pair} at {current_price}, Confidence: {confidence}%")
            except Exception as e:
                logger.error(f"Error processing data point {i} for {pair}-{timeframe}: {e}")
                skip_count += 1
                continue
        
        logger.info(f"âœ… Generated {signal_count} signals for {pair}-{timeframe} ({skip_count} points skipped)")
        
        # Jika masih tidak ada sinyal, buat sample signals untuk testing
        if signal_count == 0:
            logger.warning("No signals generated, creating sample signals for testing")
            sample_indices = random.sample(range(len(df)), min(10, len(df)))
            for idx in sample_indices:
                current_data = df.iloc[:idx+1]
                current_date = current_data.iloc[-1]['date']
                current_price = current_data.iloc[-1]['close']
                
                action = random.choice(['BUY', 'SELL'])
                signals.append({
                    'date': current_date,
                    'pair': pair,
                    'action': action,
                    'tp': random.randint(25, 45),
                    'sl': random.randint(15, 25),
                    'lot_size': Config.DEFAULT_LOT_SIZE,
                    'confidence': random.randint(40, 70),
                    'strength': random.choice(['MODERATE', 'STRONG']),
                    'volatility': 1.5,
                    'trend_strength': 0.5
                })
                signal_count += 1
            logger.info(f"âœ… Created {signal_count} sample signals for testing")
        
        return signals
        
    except Exception as e:
        logger.error(f"Error generating backtest signals: {e}")
        traceback.print_exc()
        return signals

# ---------------- DATA LOADING & SAMPLE DATA ----------------
def load_csv_data():
    """Load historical CSV data"""
    search_dirs = [".", "data", "historical_data"]
    loaded_count = 0
    
    for directory in search_dirs:
        if not os.path.exists(directory):
            continue
            
        for filename in os.listdir(directory):
            if filename.endswith(".csv"):
                file_path = os.path.join(directory, filename)
                try:
                    df = pd.read_csv(file_path)
                    
                    # Standardize column names
                    df.columns = [str(col).lower().strip().replace(' ', '_').replace('.', '') for col in df.columns]
                    
                    # Handle date parsing
                    date_column = None
                    for col in ['date', 'time', 'datetime', 'timestamp']:
                        if col in df.columns:
                            date_column = col
                            break
                    
                    if date_column:
                        df[date_column] = pd.to_datetime(df[date_column], errors='coerce')
                        df = df.dropna(subset=[date_column])
                        df = df.sort_values(date_column)
                    
                    # Extract pair and timeframe from filename
                    base_name = os.path.basename(filename).replace(".csv", "").upper()
                    parts = base_name.split("_")
                    pair = parts[0] if parts else "UNKNOWN"
                    timeframe = parts[1] if len(parts) > 1 else "1D"
                    
                    if pair not in Config.SUPPORTED_PAIRS:
                        continue
                    
                    if pair not in HISTORICAL:
                        HISTORICAL[pair] = {}
                    
                    HISTORICAL[pair][timeframe] = df
                    loaded_count += 1
                    logger.info(f"âœ… Loaded {pair}-{timeframe} from {file_path}, {len(df)} rows")
                    
                except Exception as e:
                    logger.error(f"Error loading {file_path}: {e}")
    
    logger.info(f"Total loaded datasets: {loaded_count}")

    if HISTORICAL:
        backtester.load_historical_data(HISTORICAL)
        logger.info("âœ… Historical data loaded to backtester")

def create_sample_data():
    """Create sample historical data if none exists"""
    try:
        if not os.path.exists('historical_data'):
            os.makedirs('historical_data')
        
        pairs = ['USDJPY', 'GBPJPY', 'EURJPY', 'CHFJPY']
        timeframes = ['1H', '4H', '1D']
        
        base_prices = {
            'USDJPY': 147.0,
            'GBPJPY': 198.0, 
            'EURJPY': 172.0,
            'CHFJPY': 184.0
        }
        
        for pair in pairs:
            for timeframe in timeframes:
                filename = f"historical_data/{pair}_{timeframe}.csv"
                
                if os.path.exists(filename):
                    continue
                
                logger.info(f"Creating sample data for {pair}-{timeframe}")
                
                periods = 1000
                base_price = base_prices[pair]
                prices = []
                current_price = base_price
                
                # Add realistic trends and patterns
                trend_periods = [50, 100, 200]
                current_trend = 0
                trend_duration = 0
                trend_direction = 1
                
                for i in range(periods):
                    # Change trend occasionally
                    if trend_duration <= 0:
                        trend_direction = random.choice([-1, 1])
                        trend_duration = random.choice(trend_periods)
                        current_trend = trend_direction * random.uniform(0.1, 0.5)
                    else:
                        trend_duration -= 1
                    
                    open_price = current_price
                    trend_move = current_trend * (random.random() * 0.1)
                    random_move = (random.random() - 0.5) * 2 * 0.01
                    
                    close = open_price + trend_move + random_move
                    
                    high = max(open_price, close) + abs(random_move) * 0.3
                    low = min(open_price, close) - abs(random_move) * 0.3
                    
                    # Generate dates based on timeframe
                    if timeframe == '1H':
                        current_date = datetime(2023, 1, 1) + timedelta(hours=i)
                    elif timeframe == '4H':
                        current_date = datetime(2023, 1, 1) + timedelta(hours=4*i)
                    else:  # 1D
                        current_date = datetime(2023, 1, 1) + timedelta(days=i)
                    
                    prices.append({
                        'date': current_date,
                        'open': round(open_price, 4),
                        'high': round(high, 4),
                        'low': round(low, 4),
                        'close': round(close, 4),
                        'volume': int(10000 + random.random() * 10000)
                    })
                    
                    current_price = close
                
                df = pd.DataFrame(prices)
                df.to_csv(filename, index=False)
                logger.info(f"âœ… Created sample data: {filename} with {len(df)} rows")
                
        logger.info("Sample data creation completed")
        
    except Exception as e:
        logger.error(f"Error creating sample data: {e}")

# ---------------- FLASK ROUTES ----------------
@app.route('/')
def index():
    return render_template('index.html', 
                         pairs=Config.SUPPORTED_PAIRS,
                         timeframes=Config.SUPPORTED_TIMEFRAMES,
                         ai_available=bool(DEEPSEEK_API_KEY and DEEPSEEK_API_KEY != "demo"))

@app.route('/static/<path:path>')
def serve_static(path):
    return send_from_directory('static', path)

@app.route('/performance')
def performance():
    """Performance dashboard page"""
    return render_template('performance.html')

@app.route('/api/performance_metrics')
def api_performance_metrics():
    """API endpoint for performance metrics dengan error handling yang lebih baik"""
    try:
        conn = sqlite3.connect(Config.DB_PATH)
        c = conn.cursor()
        
        # Check if table exists first
        c.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='backtesting_results'")
        table_exists = c.fetchone()
        
        if not table_exists:
            logger.warning("Table 'backtesting_results' does not exist yet")
            return jsonify({
                'metrics': [],
                'overall_stats': {
                    'avg_win_rate': 0,
                    'total_profit_all': 0,
                    'best_pair': {},
                    'total_tests': 0,
                    'message': 'No backtest data available. Run some backtests first.'
                }
            })
        
        # Get recent backtest results for performance metrics
        c.execute('''
            SELECT pair, timeframe, win_rate, total_profit, final_balance, max_drawdown, profit_factor, timestamp
            FROM backtesting_results 
            ORDER BY timestamp DESC LIMIT 20
        ''')
        
        results = c.fetchall()
        metrics = []
        
        for row in results:
            metrics.append({
                'pair': row[0] or 'Unknown',
                'timeframe': row[1] or '4H',
                'win_rate': float(row[2]) if row[2] is not None else 0,
                'total_profit': float(row[3]) if row[3] is not None else 0,
                'final_balance': float(row[4]) if row[4] is not None else Config.INITIAL_BALANCE,
                'max_drawdown': float(row[5]) if row[5] is not None else 0,
                'profit_factor': float(row[6]) if row[6] is not None else 0,
                'timestamp': row[7] or datetime.now().isoformat()
            })
        
        logger.info(f"Found {len(metrics)} backtest records for performance metrics")
        
        # Calculate overall stats
        if metrics and len(metrics) > 0:
            win_rates = [m['win_rate'] for m in metrics if m['win_rate'] is not None]
            total_profits = [m['total_profit'] for m in metrics if m['total_profit'] is not None]
            
            if win_rates:
                avg_win_rate = round(sum(win_rates) / len(win_rates), 2)
                best_pair = max(metrics, key=lambda x: x.get('win_rate', 0))
            else:
                avg_win_rate = 0
                best_pair = {}
                
            if total_profits:
                total_profit_all = round(sum(total_profits), 2)
            else:
                total_profit_all = 0
            
            overall_stats = {
                'avg_win_rate': avg_win_rate,
                'total_profit_all': total_profit_all,
                'best_pair': best_pair,
                'total_tests': len(metrics),
                'message': f'Loaded {len(metrics)} backtest results'
            }
        else:
            overall_stats = {
                'avg_win_rate': 0,
                'total_profit_all': 0,
                'best_pair': {},
                'total_tests': 0,
                'message': 'No backtest results found in database'
            }
        
        conn.close()
        
        response_data = {
            'metrics': metrics,
            'overall_stats': overall_stats,
            'status': 'success'
        }
        
        logger.info(f"Performance metrics response: {overall_stats}")
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"Error fetching performance metrics: {e}")
        traceback.print_exc()
        return jsonify({
            'error': str(e),
            'metrics': [],
            'overall_stats': {
                'avg_win_rate': 0,
                'total_profit_all': 0,
                'best_pair': {},
                'total_tests': 0,
                'message': f'Error: {str(e)}'
            },
            'status': 'error'
        }), 500

@app.route('/api/debug_database')
def api_debug_database():
    """Debug endpoint to check database contents"""
    try:
        conn = sqlite3.connect(Config.DB_PATH)
        c = conn.cursor()
        
        # Check tables
        c.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = c.fetchall()
        
        result = {
            'tables': [table[0] for table in tables],
            'backtesting_results_count': 0,
            'backtesting_results_sample': []
        }
        
        if 'backtesting_results' in result['tables']:
            c.execute("SELECT COUNT(*) FROM backtesting_results")
            result['backtesting_results_count'] = c.fetchone()[0]
            
            c.execute("SELECT pair, timeframe, win_rate, total_profit, timestamp FROM backtesting_results ORDER BY timestamp DESC LIMIT 5")
            sample = c.fetchall()
            result['backtesting_results_sample'] = [
                {
                    'pair': row[0],
                    'timeframe': row[1], 
                    'win_rate': row[2],
                    'total_profit': row[3],
                    'timestamp': row[4]
                } for row in sample
            ]
        
        conn.close()
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/get_analysis')
def get_analysis():
    start_time = datetime.now()
    
    try:
        pair = request.args.get("pair", "USDJPY").upper()
        timeframe = request.args.get("timeframe", "4H").upper()
        use_history = request.args.get("use_history", "0") == "1"
        
        logger.info(f"Analysis request: {pair}-{timeframe}")
        
        if pair not in Config.SUPPORTED_PAIRS:
            return jsonify({"error": f"Unsupported pair: {pair}"}), 400
        
        if timeframe not in Config.SUPPORTED_TIMEFRAMES:
            return jsonify({"error": f"Unsupported timeframe: {timeframe}"}), 400
        
        # Get real-time price
        current_price = None
        data_source = "Fallback"
        
        if TWELVE_API_KEY and TWELVE_API_KEY != "demo":
            try:
                symbol = f"{pair[:3]}/{pair[3:]}"
                url = f"https://api.twelvedata.com/exchange_rate?symbol={symbol}&apikey={TWELVE_API_KEY}"
                response = requests.get(url, timeout=Config.REQUEST_TIMEOUT)
                if response.status_code == 200:
                    data = response.json()
                    if "rate" in data:
                        current_price = float(data["rate"])
                        data_source = "Twelve Data"
                        logger.info(f"Real price for {pair}: {current_price}")
            except Exception as e:
                logger.warning(f"TwelveData unavailable: {e}")
        
        # Fallback to historical data
        if current_price is None and pair in HISTORICAL and timeframe in HISTORICAL[pair]:
            current_price = float(HISTORICAL[pair][timeframe].tail(1)["close"].iloc[0])
            data_source = "Historical CSV"
        elif current_price is None:
            base_prices = {"USDJPY": 147.0, "GBPJPY": 198.0, "EURJPY": 172.0, "CHFJPY": 184.0}
            current_price = base_prices.get(pair, 150.0)
            data_source = "Synthetic"
        
        # Get historical data for indicators
        required_bars = Config.DATA_PERIODS.get(timeframe, 100)
        
        if use_history and pair in HISTORICAL and timeframe in HISTORICAL[pair]:
            df = HISTORICAL[pair][timeframe].tail(required_bars)
            closes = df["close"].tolist()
            volumes = df["volume"].fillna(0).tolist() if "volume" in df.columns else None
            
            # Format dates based on timeframe
            if timeframe == '1D':
                dates = df["date"].dt.strftime("%d/%m/%Y").tolist()
            elif timeframe == '1W':
                dates = df["date"].dt.strftime("%d/%m/%y").tolist()
            else:
                dates = df["date"].dt.strftime("%d/%m %H:%M").tolist()
            
            close_series = pd.Series(closes)
            ema200_series = calculate_ema_series(close_series, 200)
            ema200_values = [round(x, 4) for x in ema200_series.tolist()]
            
            macd_line, macd_signal, macd_histogram = calculate_macd_series(close_series)
            macd_line_values = [round(x, 4) for x in macd_line.tolist()]
            macd_signal_values = [round(x, 4) for x in macd_signal.tolist()]
            macd_histogram_values = [round(x, 4) for x in macd_histogram.tolist()]
            
        else:
            # Generate synthetic data
            num_points = required_bars
            base_price = current_price
            closes = []
            for i in range(num_points):
                if i == 0:
                    closes.append(base_price)
                else:
                    prev_price = closes[-1]
                    change = random.uniform(-0.002, 0.002) * prev_price
                    new_price = prev_price + change
                    closes.append(new_price)
            
            volumes = [random.randint(8000, 15000) for _ in range(num_points)]
            
            # Generate dates based on timeframe
            base_date = datetime.now()
            if timeframe == '1D':
                dates = [(base_date - timedelta(days=i)).strftime("%d/%m/%Y") 
                        for i in range(num_points-1, -1, -1)]
            elif timeframe == '4H':
                dates = [(base_date - timedelta(hours=4*i)).strftime("%d/%m %H:%M") 
                        for i in range(num_points-1, -1, -1)]
            elif timeframe == '1W':
                dates = [(base_date - timedelta(weeks=i)).strftime("%d/%m/%y") 
                        for i in range(num_points-1, -1, -1)]
            else:
                dates = [(base_date - timedelta(hours=i)).strftime("%d/%m %H:%M") 
                        for i in range(num_points-1, -1, -1)]
            
            close_series = pd.Series(closes)
            ema200_series = calculate_ema_series(close_series, 200)
            ema200_values = [round(x, 4) for x in ema200_series.tolist()]
            
            macd_line, macd_signal, macd_histogram = calculate_macd_series(close_series)
            macd_line_values = [round(x, 4) for x in macd_line.tolist()]
            macd_signal_values = [round(x, 4) for x in macd_signal.tolist()]
            macd_histogram_values = [round(x, 4) for x in macd_histogram.tolist()]
        
        # Calculate technical indicators
        technical_indicators = calc_indicators(closes, volumes)
        
        # Get REAL fundamental news
        fundamental_news = get_real_news(pair)
        
        # AI Analysis with DeepSeek
        ai_analysis = ai_deepseek_analysis(pair, technical_indicators, fundamental_news)
        
        # Prepare response
        response_data = {
            "pair": pair,
            "timeframe": timeframe,
            "timestamp": datetime.now().isoformat(),
            "current_price": current_price,
            "technical_indicators": technical_indicators,
            "ai_analysis": ai_analysis,
            "fundamental_news": fundamental_news,
            "chart_data": {
                "dates": dates,
                "close": closes,
                "volume": volumes,
                "ema200": ema200_values,
                "macd_line": macd_line_values,
                "macd_signal": macd_signal_values,
                "macd_histogram": macd_histogram_values
            },
            "data_source": data_source,
            "processing_time": round((datetime.now() - start_time).total_seconds(), 2),
            "ai_provider": ai_analysis.get("AI_PROVIDER", "Fallback System")
        }
        
        # Save to database
        save_analysis_result(response_data)
        
        logger.info(f"Analysis completed for {pair}-{timeframe} in {response_data['processing_time']}s")
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"Analysis error: {e}")
        traceback.print_exc()
        return jsonify({"error": f"Analysis failed: {str(e)}"}), 500

@app.route('/api/run_backtest', methods=['POST'])
def api_run_backtest():
    try:
        data = request.get_json()
        pair = data.get('pair', 'USDJPY')
        timeframe = data.get('timeframe', '4H')
        days = data.get('days', 30)
        
        logger.info(f"Backtest request: {pair}-{timeframe} for {days} days")
        
        if pair not in Config.SUPPORTED_PAIRS:
            return jsonify({'error': f'Unsupported pair: {pair}'}), 400
        
        if timeframe not in Config.SUPPORTED_TIMEFRAMES:
            return jsonify({'error': f'Unsupported timeframe: {timeframe}'}), 400
        
        if pair not in HISTORICAL or timeframe not in HISTORICAL[pair]:
            return jsonify({
                'error': f'No historical data found for {pair}-{timeframe}',
                'suggestion': 'Please ensure CSV files exist in historical_data folder'
            }), 400
        
        signals = generate_backtest_signals_from_analysis(pair, timeframe, days)
        
        if not signals:
            return jsonify({
                'status': 'error',
                'message': 'No signals generated for backtesting',
                'recommendations': [
                    'Adjust signal parameters to be less strict',
                    'Try different timeframe or currency pair',
                    'Check if historical data is available'
                ]
            }), 200  # Tetap return 200 agar frontend bisa menampilkan pesan
        
        report = backtester.run_backtest(signals, timeframe)
        
        # Add metadata
        report['metadata'] = {
            'pair': pair,
            'timeframe': timeframe,
            'period_days': days,
            'signals_generated': len(signals),
            'initial_balance': Config.INITIAL_BALANCE,
            'data_points_used': len(HISTORICAL[pair][timeframe]) if pair in HISTORICAL and timeframe in HISTORICAL[pair] else 0
        }
        
        # Save to database dan cek hasilnya
        save_success = save_backtest_result(report)
        report['save_success'] = save_success
        
        if save_success:
            logger.info(f"âœ… Backtest completed and saved successfully with {len(signals)} signals")
        else:
            logger.error("âŒ Backtest completed but failed to save to database")
        
        return jsonify(report)
        
    except Exception as e:
        logger.error(f"Backtesting error: {e}")
        traceback.print_exc()
        return jsonify({
            'status': 'error',
            'message': f'Backtesting failed: {str(e)}',
            'recommendations': ['Check server logs for detailed error information']
        }), 500

@app.route('/api/backtest_history')
def api_backtest_history():
    try:
        conn = sqlite3.connect(Config.DB_PATH)
        c = conn.cursor()
        
        c.execute('''SELECT pair, timeframe, period_days, total_trades, winning_trades, 
                    win_rate, total_profit, final_balance, max_drawdown, profit_factor, timestamp
                    FROM backtesting_results 
                    ORDER BY timestamp DESC LIMIT 10''')
        
        results = c.fetchall()
        history = []
        
        for row in results:
            history.append({
                'pair': row[0],
                'timeframe': row[1],
                'period_days': row[2],
                'total_trades': row[3],
                'winning_trades': row[4],
                'win_rate': row[5],
                'total_profit': row[6],
                'final_balance': row[7],
                'max_drawdown': row[8],
                'profit_factor': row[9],
                'timestamp': row[10]
            })
        
        conn.close()
        return jsonify(history)
        
    except Exception as e:
        logger.error(f"Error fetching backtest history: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/quick_overview')
def quick_overview():
    overview = {}
    
    for pair in Config.SUPPORTED_PAIRS:
        try:
            price = None
            source = "Fallback"
            
            if TWELVE_API_KEY and TWELVE_API_KEY != "demo":
                try:
                    symbol = f"{pair[:3]}/{pair[3:]}"
                    url = f"https://api.twelvedata.com/exchange_rate?symbol={symbol}&apikey={TWELVE_API_KEY}"
                    response = requests.get(url, timeout=10)
                    if response.status_code == 200:
                        data = response.json()
                        if "rate" in data:
                            price = float(data["rate"])
                            source = "Twelve Data"
                except:
                    pass
            
            if price is None and pair in HISTORICAL and "1D" in HISTORICAL[pair]:
                price = float(HISTORICAL[pair]["1D"].tail(1)["close"].iloc[0])
                source = "Historical"
            elif price is None:
                base_prices = {"USDJPY": 147.0, "GBPJPY": 198.0, "EURJPY": 172.0, "CHFJPY": 184.0}
                price = base_prices.get(pair, 150.0)
                source = "Synthetic"
            
            if pair in HISTORICAL and "1D" in HISTORICAL[pair]:
                df = HISTORICAL[pair]["1D"]
                if len(df) > 1:
                    prev_close = df.iloc[-2]['close']
                    change_pct = ((price - prev_close) / prev_close) * 100
                else:
                    change_pct = 0
            else:
                change_pct = random.uniform(-0.3, 0.3)
            
            overview[pair] = {
                "price": round(price, 4),
                "change": round(change_pct, 2),
                "source": source,
                "trend": "up" if change_pct > 0 else "down" if change_pct < 0 else "flat"
            }
            
        except Exception as e:
            logger.error(f"Quick overview error for {pair}: {e}")
            overview[pair] = {
                "price": None,
                "change": 0,
                "source": "error",
                "trend": "flat"
            }
    
    return jsonify(overview)

@app.route('/ai_status')
def ai_status():
    status = {
        "ai_available": bool(DEEPSEEK_API_KEY and DEEPSEEK_API_KEY != "demo"),
        "news_available": bool(NEWS_API_KEY and NEWS_API_KEY != "demo"),
        "price_available": bool(TWELVE_API_KEY and TWELVE_API_KEY != "demo"),
        "ai_provider": "DeepSeek",
        "news_provider": "NewsAPI",
        "price_provider": "Twelve Data",
        "message": "All systems operational" if (DEEPSEEK_API_KEY and NEWS_API_KEY and TWELVE_API_KEY) else "Some features disabled - check API keys"
    }
    return jsonify(status)

# ---------------- RESET & MAINTENANCE ROUTES ----------------
@app.route('/api/reset_backtest_data', methods=['POST'])
def api_reset_backtest_data():
    """Reset all backtest data from database"""
    try:
        conn = sqlite3.connect(Config.DB_PATH)
        c = conn.cursor()
        
        # Reset backtesting_results table
        c.execute('DELETE FROM backtesting_results')
        
        # Reset analysis_results table (optional)
        # c.execute('DELETE FROM analysis_results')
        
        conn.commit()
        conn.close()
        
        logger.info("âœ… Backtest data reset successfully")
        return jsonify({
            'status': 'success',
            'message': 'All backtest data has been reset successfully',
            'reset_tables': ['backtesting_results']
        })
        
    except Exception as e:
        logger.error(f"Error resetting backtest data: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/reset_database', methods=['POST'])
def api_reset_database():
    """Complete database reset - recreates all tables"""
    try:
        # Initialize database (will recreate tables)
        init_db()
        
        logger.info("âœ… Database completely reset")
        return jsonify({
            'status': 'success',
            'message': 'Database completely reset - all tables recreated',
            'reset_tables': ['analysis_results', 'backtesting_results']
        })
        
    except Exception as e:
        logger.error(f"Error resetting database: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/database_stats')
def api_database_stats():
    """Get database statistics"""
    try:
        conn = sqlite3.connect(Config.DB_PATH)
        c = conn.cursor()
        
        stats = {}
        
        # Count records in each table
        c.execute("SELECT COUNT(*) FROM backtesting_results")
        stats['backtesting_records'] = c.fetchone()[0]
        
        c.execute("SELECT COUNT(*) FROM analysis_results")
        stats['analysis_records'] = c.fetchone()[0]
        
        # Get latest backtest dates
        c.execute("SELECT MAX(timestamp) FROM backtesting_results")
        stats['latest_backtest'] = c.fetchone()[0]
        
        c.execute("SELECT MAX(timestamp) FROM analysis_results")
        stats['latest_analysis'] = c.fetchone()[0]
        
        # Get table sizes
        c.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = c.fetchall()
        
        table_sizes = {}
        for table in tables:
            table_name = table[0]
            c.execute(f"SELECT COUNT(*) FROM {table_name}")
            table_sizes[table_name] = c.fetchone()[0]
        
        stats['table_sizes'] = table_sizes
        
        conn.close()
        
        return jsonify({
            'status': 'success',
            'stats': stats,
            'database_path': Config.DB_PATH
        })
        
    except Exception as e:
        logger.error(f"Error getting database stats: {e}")
        return jsonify({'error': str(e)}), 500
# ---------------- INITIALIZATION ----------------
if __name__ == "__main__":
    logger.info("ðŸš€ Starting Enhanced Forex Analysis Application...")
    
    # Initialize database
    init_db()
    
    # Create sample data if needed
    create_sample_data()
    
    # Load historical data
    load_csv_data()
    
    # Log system status
    logger.info("=== SYSTEM STATUS ===")
    logger.info(f"DeepSeek AI: {'âœ… ENABLED' if DEEPSEEK_API_KEY and DEEPSEEK_API_KEY != 'demo' else 'âŒ DISABLED'}")
    logger.info(f"News API: {'âœ… ENABLED' if NEWS_API_KEY and NEWS_API_KEY != 'demo' else 'âŒ DISABLED'}")
    logger.info(f"Price API: {'âœ… ENABLED' if TWELVE_API_KEY and TWELVE_API_KEY != 'demo' else 'âŒ DISABLED'}")
    logger.info(f"Historical Data: {len(HISTORICAL)} pairs loaded")
    
    for pair in HISTORICAL:
        for tf in HISTORICAL[pair]:
            logger.info(f"  {pair}-{tf}: {len(HISTORICAL[pair][tf])} data points")
    
    logger.info("=====================")
    
    # Start Flask application
    app.run(debug=True, host='0.0.0.0', port=5000)
