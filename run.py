from flask import Flask, jsonify, request, render_template
from flask_cors import CORS
import pandas as pd
import numpy as np
import requests
import json
from datetime import datetime, timedelta
import os
import traceback
import time
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Try to import talib
try:
    import talib
    TALIB_AVAILABLE = True
    print("‚úÖ TA-Lib is available")
except ImportError:
    print("‚ö†Ô∏è TA-Lib not available, using fallback calculations")
    TALIB_AVAILABLE = False

app = Flask(__name__)
CORS(app)

# Setup template folder
template_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'templates')
app.template_folder = template_dir

class XAUUSDAnalyzer:
    def __init__(self):
        self.data_cache = {}
        self.twelve_data_api_key = os.getenv('TWELVE_DATA_API_KEY')
        self.deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')
        self.news_api_key = os.getenv('NEWS_API_KEY')
        self.last_api_call = 0
        
        print(f"üîë API Keys loaded: TwelveData: {'‚úÖ' if self.twelve_data_api_key else '‚ùå'}, "
              f"DeepSeek: {'‚úÖ' if self.deepseek_api_key else '‚ùå'}, "
              f"NewsAPI: {'‚úÖ' if self.news_api_key else '‚ùå'}")

    def debug_data_quality(self, df, column_name):
        """Debug data quality for a specific column"""
        if column_name in df.columns:
            series = df[column_name]
            print(f"  {column_name}: min={series.min():.2f}, max={series.max():.2f}, "
                  f"mean={series.mean():.2f}, nulls={series.isnull().sum()}, unique={series.nunique()}")

    def load_from_local_csv(self, timeframe, limit=500):
        """Load data dari file CSV lokal"""
        possible_paths = [
            f"data/XAUUSD_{timeframe}.csv",
            f"../data/XAUUSD_{timeframe}.csv",
            f"./data/XAUUSD_{timeframe}.csv",
            f"XAUUSD_{timeframe}.csv"
        ]
        
        for filename in possible_paths:
            if os.path.exists(filename):
                try:
                    print(f"üìÅ Loading from {filename}")
                    df = pd.read_csv(filename)
                    
                    print(f"üìä Columns in CSV: {df.columns.tolist()}")
                    
                    # Pastikan kolom datetime ada dan format benar
                    datetime_col = None
                    for col in ['datetime', 'date', 'time', 'timestamp']:
                        if col in df.columns:
                            datetime_col = col
                            break
                    
                    if datetime_col:
                        df['datetime'] = pd.to_datetime(df[datetime_col])
                        if datetime_col != 'datetime':
                            df = df.drop(columns=[datetime_col])
                    else:
                        print("‚ö†Ô∏è No datetime column found, creating based on index")
                        if timeframe == '1H':
                            freq = 'H'
                        elif timeframe == '4H':
                            freq = '4H'
                        else:
                            freq = 'D'
                        df['datetime'] = pd.date_range(end=datetime.now(), periods=len(df), freq=freq)
                    
                    # Pastikan kolom OHLC ada
                    ohlc_mapping = {
                        'open': ['open', 'Open', 'OPEN'],
                        'high': ['high', 'High', 'HIGH'], 
                        'low': ['low', 'Low', 'LOW'],
                        'close': ['close', 'Close', 'CLOSE']
                    }
                    
                    for standard_name, possible_names in ohlc_mapping.items():
                        if standard_name not in df.columns:
                            for name in possible_names:
                                if name in df.columns:
                                    df[standard_name] = df[name]
                                    print(f"üîÄ Mapped column {name} to {standard_name}")
                                    break
                    
                    # Pastikan kolom volume ada
                    if 'volume' not in df.columns:
                        print("üìà Volume column not found, setting default values")
                        df['volume'] = np.random.randint(1000, 10000, len(df))
                    
                    # Konversi ke numeric dan handle missing values
                    for col in ['open', 'high', 'low', 'close', 'volume']:
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                        df[col] = df[col].fillna(method='ffill').fillna(method='bfill')
                    
                    df = df.sort_values('datetime')
                    print(f"‚úÖ Successfully loaded {len(df)} records from {filename}")
                    
                    # Debug data quality
                    print("üîç Data quality check:")
                    self.debug_data_quality(df, 'open')
                    self.debug_data_quality(df, 'high')
                    self.debug_data_quality(df, 'low')
                    self.debug_data_quality(df, 'close')
                    
                    return df.tail(limit)
                except Exception as e:
                    print(f"‚ùå Error processing {filename}: {e}")
                    continue
        return None

    def download_historical_data(self, timeframe, days=30):
        """Download data historis dari Twelve Data API"""
        try:
            if not self.twelve_data_api_key:
                print("‚ùå Twelve Data API key not available for historical data download")
                return None
                
            interval_map = {
                '1H': '1h',
                '4H': '4h', 
                '1D': '1day'
            }
            
            interval = interval_map.get(timeframe, '1h')
            url = f"https://api.twelvedata.com/time_series?symbol=XAU/USD&interval={interval}&outputsize=1000&apikey={self.twelve_data_api_key}"
            
            response = requests.get(url, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                if data.get('status') == 'ok' and 'values' in data:
                    values = data['values']
                    df = pd.DataFrame(values)
                    
                    df = df.rename(columns={
                        'datetime': 'datetime',
                        'open': 'open',
                        'high': 'high', 
                        'low': 'low',
                        'close': 'close'
                    })
                    
                    df['datetime'] = pd.to_datetime(df['datetime'])
                    for col in ['open', 'high', 'low', 'close']:
                        df[col] = pd.to_numeric(df[col])
                    
                    if 'volume' not in df.columns:
                        df['volume'] = 10000
                    
                    df = df.sort_values('datetime')
                    
                    filename = f"data/XAUUSD_{timeframe}.csv"
                    df.to_csv(filename, index=False)
                    print(f"‚úÖ Downloaded and saved {len(df)} records to {filename}")
                    
                    return df
                else:
                    print(f"‚ùå Twelve Data API error: {data.get('message', 'Unknown error')}")
                    return None
            else:
                print(f"‚ùå Twelve Data API HTTP error: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error downloading historical data: {e}")
            return None

    def aggressive_data_cleaning(self, df):
        """Aggressive data cleaning untuk CSV yang bermasalah"""
        print("üö® AGGRESSIVE Data Cleaning Activated")
        
        if len(df) < 50:
            return df
            
        initial_count = len(df)
        
        # Filter untuk harga gold yang realistis
        df = df[(df['close'] >= 1800) & (df['close'] <= 4500)]
        df = df[(df['high'] >= 1800) & (df['high'] <= 4500)]
        df = df[(df['low'] >= 1800) & (df['low'] <= 4500)]
        df = df[(df['open'] >= 1800) & (df['open'] <= 4500)]
        
        # Hapus outliers berdasarkan IQR method
        for col in ['close', 'high', 'low', 'open']:
            if col in df.columns:
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
        
        # Pastikan data terurut dan konsisten
        df = df.sort_values('datetime')
        df = df.reset_index(drop=True)
        
        final_count = len(df)
        removed_count = initial_count - final_count
        
        if removed_count > 0:
            print(f"üö® Removed {removed_count} problematic records")
            print(f"üìä Final data range: ${df['close'].min():.2f} - ${df['close'].max():.2f}")
        
        return df

    def enhanced_data_validation(self, df):
        """Enhanced data validation dengan outlier detection"""
        print("üîç Enhanced data validation...")
        
        if df is None or len(df) == 0:
            return False
            
        # Check for realistic gold price range
        current_price = df['close'].iloc[-1]
        if current_price < 1800 or current_price > 4500:
            print(f"‚ùå CRITICAL: Unrealistic gold price: ${current_price:.2f}")
            return False
        
        # Check price relationships
        invalid_high_low = (df['high'] < df['low']).sum()
        invalid_open_close = (df['open'] <= 0).sum() | (df['close'] <= 0).sum()
        
        if invalid_high_low > 0 or invalid_open_close > 0:
            print(f"‚ùå CRITICAL: Invalid price relationships detected")
            return False
        
        # Check for reasonable volatility
        daily_returns = df['close'].pct_change().abs()
        extreme_moves = (daily_returns > 0.05).sum()  # More than 5% moves
        
        if extreme_moves > len(df) * 0.1:  # More than 10% of data has extreme moves
            print(f"‚ùå CRITICAL: Too many extreme price moves: {extreme_moves}")
            return False
            
        print("‚úÖ Enhanced data validation passed")
        return True

    def load_historical_data(self, timeframe, limit=500):
        """Load data historis dengan aggressive cleaning"""
        try:
            # Try local CSV first
            df = self.load_from_local_csv(timeframe, limit)
            if df is not None:
                # Apply aggressive cleaning
                df = self.aggressive_data_cleaning(df)
                if len(df) >= 50:  # Minimal data setelah cleaning
                    print(f"‚úÖ Using aggressively cleaned local data for {timeframe}")
                    return df.tail(limit)
                else:
                    print("‚ùå Insufficient data after aggressive cleaning")
                    
            # Try download if local data invalid
            print(f"üì• Local data invalid, trying to download for {timeframe}...")
            df = self.download_historical_data(timeframe)
            if df is not None and self.enhanced_data_validation(df):
                print(f"‚úÖ Using downloaded data for {timeframe}")
                return df.tail(limit)
                
            # Final fallback - generate realistic sample data
            print(f"üîÑ All methods failed, using realistic generated data for {timeframe}")
            return self.generate_realistic_sample_data(timeframe, limit)
            
        except Exception as e:
            print(f"‚ùå Error in load_historical_data: {e}")
            return self.generate_realistic_sample_data(timeframe, limit)

    def generate_realistic_sample_data(self, timeframe, limit=500):
        """Generate realistic sample data based on current gold prices"""
        print(f"üîÑ Generating REALISTIC sample data for {timeframe}")
        
        periods = limit
        # Use realistic base price for gold (current approximate)
        base_price = 4237.0
        
        if timeframe == '1H':
            freq = 'H'
            volatility = 0.002  # 0.2% hourly volatility
        elif timeframe == '4H':
            freq = '4H' 
            volatility = 0.004  # 0.4% 4-hour volatility
        else:
            freq = 'D'
            volatility = 0.008  # 0.8% daily volatility
            
        dates = pd.date_range(end=datetime.now(), periods=periods, freq=freq)
        
        np.random.seed(42)
        returns = np.random.normal(0, volatility, periods)
        prices = base_price * (1 + returns).cumprod()
        
        data = []
        for i in range(periods):
            open_price = prices[i]
            close_price = prices[i] * np.random.uniform(0.998, 1.002)
            high_price = max(open_price, close_price) * np.random.uniform(1.001, 1.015)
            low_price = min(open_price, close_price) * np.random.uniform(0.985, 0.999)
            
            # Ensure high > low and reasonable ranges
            high_price = max(high_price, open_price, close_price)
            low_price = min(low_price, open_price, close_price)
            
            data.append({
                'datetime': dates[i],
                'open': round(open_price, 2),
                'high': round(high_price, 2),
                'low': round(low_price, 2),
                'close': round(close_price, 2),
                'volume': np.random.randint(10000, 100000)
            })
        
        df = pd.DataFrame(data)
        
        self.data_cache[timeframe] = df
        print(f"‚úÖ Generated {len(df)} realistic records for {timeframe}")
        return df

    def clean_and_validate_data(self, df):
        """Enhanced data cleaning and validation"""
        print("üßπ Cleaning and validating dataframe...")
        
        if df is None or len(df) == 0:
            print("‚ùå Empty dataframe provided")
            return df
            
        # Convert to numeric
        for col in ['open', 'high', 'low', 'close', 'volume']:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # Remove rows with missing critical data
        initial_count = len(df)
        df = df.dropna(subset=['open', 'high', 'low', 'close'])
        removed_count = initial_count - len(df)
        if removed_count > 0:
            print(f"‚ö†Ô∏è Removed {removed_count} rows with missing data")
        
        # Forward fill then backward fill
        df = df.fillna(method='ffill').fillna(method='bfill')
        
        # Remove extreme outliers (prices beyond 3 standard deviations)
        for col in ['open', 'high', 'low', 'close']:
            if col in df.columns:
                mean = df[col].mean()
                std = df[col].std()
                # Cap extreme values
                lower_bound = mean - 3 * std
                upper_bound = mean + 3 * std
                outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
                if outliers > 0:
                    print(f"‚ö†Ô∏è Capping {outliers} outliers in {col}")
                    df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)
        
        print(f"‚úÖ Data cleaning completed. Final data count: {len(df)}")
        return df

    def validate_price_data(self, df):
        """Validate price data for sanity"""
        if len(df) == 0:
            return False
            
        # Check for reasonable price range (Gold typically $1800-$4500)
        current_price = df['close'].iloc[-1]
        if current_price < 1800 or current_price > 4500:
            print(f"‚ùå WARNING: Unrealistic price detected: ${current_price:.2f}")
            return False
        
        # Check for reasonable daily movements (typically < 10%)
        price_changes = df['close'].pct_change().abs()
        max_change = price_changes.max()
        if max_change > 0.1:  # More than 10% daily move
            print(f"‚ùå WARNING: Extreme price movement detected: {max_change:.2%}")
            return False
            
        # Check for consistent price relationships
        invalid_high_low = (df['high'] < df['low']).sum()
        if invalid_high_low > 0:
            print(f"‚ùå WARNING: {invalid_high_low} rows have high < low")
            return False
            
        return True

    def calculate_indicators(self, df):
        """Calculate technical indicators - ENHANCED VERSION"""
        try:
            if len(df) < 50:
                print(f"‚ùå Not enough data for indicators. Have {len(df)}, need at least 50")
                return self.add_corrected_fallback_indicators(df)
                
            # Clean and validate data first
            df = self.clean_and_validate_data(df)
            
            # Validate price data sanity
            if not self.validate_price_data(df):
                print("‚ùå Price data validation failed, using fallback")
                return self.add_corrected_fallback_indicators(df)
                
            close = df['close'].values
            high = df['high'].values
            low = df['low'].values
            
            print(f"üìä Calculating indicators for {len(df)} records...")
            print(f"üí∞ Price range: ${close.min():.2f} - ${close.max():.2f}")
            
            # Use TA-Lib if available, otherwise use corrected calculations
            if TALIB_AVAILABLE:
                print("üîß Using TA-Lib for indicator calculations")
                df = self.calculate_indicators_talib(df, close, high, low)
            else:
                print("üîß Using corrected pandas calculations")
                df = self.calculate_indicators_pandas(df, close, high, low)
            
            # Enhanced verification
            if not self.enhanced_indicator_verification(df):
                print("‚ùå Indicator verification failed, recalculating with fallback")
                df = self.add_corrected_fallback_indicators(df)
            
            print("‚úÖ Indicators calculated successfully")
            return df
            
        except Exception as e:
            print(f"‚ùå Error calculating indicators: {e}")
            traceback.print_exc()
            return self.add_corrected_fallback_indicators(df)

    def calculate_indicators_talib(self, df, close, high, low):
        """Calculate indicators using TA-Lib with MACD FIX"""
        try:
            # EMA
            df['ema_12'] = talib.EMA(close, timeperiod=12)
            df['ema_26'] = talib.EMA(close, timeperiod=26)
            df['ema_50'] = talib.EMA(close, timeperiod=50)
            
            # MACD - dengan fix untuk inconsistency
            macd, macd_signal, macd_hist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)
            
            # Force fix MACD histogram jika ada inconsistency
            expected_hist = macd - macd_signal
            hist_discrepancy = np.abs(macd_hist - expected_hist)
            
            # Jika discrepancy besar, gunakan calculated value
            large_discrepancies = hist_discrepancy > 0.1
            if np.any(large_discrepancies):
                print(f"‚ö†Ô∏è  Fixing {np.sum(large_discrepancies)} MACD histogram discrepancies")
                macd_hist = expected_hist
            
            df['macd'] = macd
            df['macd_signal'] = macd_signal
            df['macd_hist'] = macd_hist
            
            # RSI
            df['rsi'] = talib.RSI(close, timeperiod=14)
            
            # Bollinger Bands
            bb_upper, bb_middle, bb_lower = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)
            df['bb_upper'] = bb_upper
            df['bb_middle'] = bb_middle
            df['bb_lower'] = bb_lower
            
            # Stochastic
            stoch_k, stoch_d = talib.STOCH(high, low, close, fastk_period=14, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)
            df['stoch_k'] = stoch_k
            df['stoch_d'] = stoch_d
            
            # Final MACD validation
            self.validate_and_fix_macd(df)
            
            print("‚úÖ TA-Lib indicators calculated successfully")
            return df
            
        except Exception as e:
            print(f"‚ùå TA-Lib calculation error: {e}, falling back to pandas")
            return self.calculate_indicators_pandas(df, close, high, low)

    def validate_and_fix_macd(self, df):
        """Validate and fix MACD calculations"""
        if len(df) == 0:
            return
            
        # Check last few rows for consistency
        check_rows = min(10, len(df))
        for i in range(-check_rows, 0):
            idx = df.index[i]
            macd = df.loc[idx, 'macd']
            macd_signal = df.loc[idx, 'macd_signal'] 
            macd_hist = df.loc[idx, 'macd_hist']
            
            expected_hist = macd - macd_signal
            discrepancy = abs(macd_hist - expected_hist)
            
            if discrepancy > 0.001:
                print(f"üîß Fixing MACD histogram at index {idx}: {macd_hist} -> {expected_hist}")
                df.loc[idx, 'macd_hist'] = expected_hist
        
        # Verify fix
        last_row = df.iloc[-1]
        macd = last_row['macd']
        macd_signal = last_row['macd_signal']
        macd_hist = last_row['macd_hist']
        expected_hist = macd - macd_signal
        
        print(f"üîç MACD Final Verification:")
        print(f"   MACD: {macd:.4f}, Signal: {macd_signal:.4f}")
        print(f"   Histogram: {macd_hist:.4f}, Expected: {expected_hist:.4f}")
        print(f"   Consistent: {abs(macd_hist - expected_hist) < 0.001}")

    def calculate_indicators_pandas(self, df, close, high, low):
        """Calculate indicators using corrected pandas methods"""
        try:
            close_series = pd.Series(close)
            high_series = pd.Series(high)
            low_series = pd.Series(low)
            
            # EMA - CORRECTED: Use proper EWM with different spans
            df['ema_12'] = close_series.ewm(span=12, adjust=False).mean()
            df['ema_26'] = close_series.ewm(span=26, adjust=False).mean()
            df['ema_50'] = close_series.ewm(span=50, adjust=False).mean()
            
            # MACD - CORRECTED: Calculate from EMAs
            df['macd'] = df['ema_12'] - df['ema_26']
            df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()
            df['macd_hist'] = df['macd'] - df['macd_signal']
            
            # RSI - CORRECTED: Proper RSI calculation
            delta = close_series.diff()
            gain = delta.where(delta > 0, 0).rolling(window=14, min_periods=1).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
            rs = gain / loss.replace(0, np.inf)
            df['rsi'] = 100 - (100 / (1 + rs))
            
            # Bollinger Bands - CORRECTED
            df['bb_middle'] = close_series.rolling(window=20, min_periods=1).mean()
            bb_std = close_series.rolling(window=20, min_periods=1).std()
            df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
            df['bb_lower'] = df['bb_middle'] - (bb_std * 2)
            
            # Stochastic - CORRECTED
            lowest_low = low_series.rolling(window=14, min_periods=1).min()
            highest_high = high_series.rolling(window=14, min_periods=1).max()
            df['stoch_k'] = 100 * (close_series - lowest_low) / (highest_high - lowest_low).replace(0, 1)
            df['stoch_d'] = df['stoch_k'].rolling(window=3, min_periods=1).mean()
            
            print("‚úÖ Pandas indicators calculated successfully")
            return df
            
        except Exception as e:
            print(f"‚ùå Pandas calculation error: {e}")
            raise

    def enhanced_indicator_verification(self, df):
        """Enhanced indicator verification"""
        if len(df) == 0:
            return False
            
        last_row = df.iloc[-1]
        
        # Check MACD consistency
        macd = last_row.get('macd', 0)
        macd_signal = last_row.get('macd_signal', 0) 
        macd_hist = last_row.get('macd_hist', 0)
        
        # Verify MACD histogram calculation
        expected_hist = macd - macd_signal
        if abs(macd_hist - expected_hist) > 0.001:
            print(f"‚ùå MACD HISTOGRAM ERROR: {macd_hist} vs expected {expected_hist}")
            return False
        
        # Check RSI range
        rsi = last_row.get('rsi', 50)
        if rsi < 0 or rsi > 100:
            print(f"‚ùå Invalid RSI value: {rsi}")
            return False
            
        # Check EMA relationships are reasonable
        ema_12 = last_row.get('ema_12', 0)
        ema_26 = last_row.get('ema_26', 0)
        ema_50 = last_row.get('ema_50', 0)
        
        if ema_12 == 0 or ema_26 == 0 or ema_50 == 0:
            print("‚ùå Zero EMA values detected")
            return False
            
        # Check if all EMAs are equal (calculation error)
        if ema_12 == ema_26 == ema_50:
            print("‚ùå All EMAs have same value - calculation error")
            return False
            
        return True

    def add_corrected_fallback_indicators(self, df):
        """Corrected fallback indicators with proper calculations"""
        print("üîÑ Using CORRECTED fallback indicators")
        
        if len(df) == 0:
            return df
            
        close = df['close'].values
        close_series = pd.Series(close)
        
        # Simple but correct calculations
        df['ema_12'] = close_series.ewm(span=12, adjust=False).mean()
        df['ema_26'] = close_series.ewm(span=26, adjust=False).mean()
        df['ema_50'] = close_series.ewm(span=50, adjust=False).mean()
        
        df['macd'] = df['ema_12'] - df['ema_26']
        df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()
        df['macd_hist'] = df['macd'] - df['macd_signal']
        
        # RSI
        delta = close_series.diff()
        gain = delta.where(delta > 0, 0).rolling(window=14, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
        rs = gain / loss.replace(0, np.inf)
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # Bollinger Bands
        df['bb_middle'] = close_series.rolling(window=20, min_periods=1).mean()
        bb_std = close_series.rolling(window=20, min_periods=1).std().fillna(10)
        df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
        df['bb_lower'] = df['bb_middle'] - (bb_std * 2)
        
        # Stochastic
        low_14 = pd.Series(df['low']).rolling(window=14, min_periods=1).min()
        high_14 = pd.Series(df['high']).rolling(window=14, min_periods=1).max()
        df['stoch_k'] = 100 * (close_series - low_14) / (high_14 - low_14).replace(0, 1)
        df['stoch_d'] = df['stoch_k'].rolling(window=3, min_periods=1).mean()
        
        # Ensure no NaN values
        df = self.ensure_no_nan_indicators(df)
        
        print("‚úÖ Corrected fallback indicators applied successfully")
        return df

    def ensure_no_nan_indicators(self, df):
        """Ensure no NaN values in indicators"""
        indicator_defaults = {
            'ema_12': df['close'].iloc[-1] if len(df) > 0 else 4237.0,
            'ema_26': df['close'].iloc[-1] if len(df) > 0 else 4237.0,
            'ema_50': df['close'].iloc[-1] if len(df) > 0 else 4237.0,
            'macd': 0,
            'macd_signal': 0,
            'macd_hist': 0,
            'rsi': 50,
            'bb_upper': df['close'].iloc[-1] * 1.02 if len(df) > 0 else 4320.0,
            'bb_middle': df['close'].iloc[-1] if len(df) > 0 else 4237.0,
            'bb_lower': df['close'].iloc[-1] * 0.98 if len(df) > 0 else 4150.0,
            'stoch_k': 50,
            'stoch_d': 50
        }
        
        for indicator, default in indicator_defaults.items():
            if indicator in df.columns:
                df[indicator] = df[indicator].fillna(default)
        
        return df

    def verify_indicator_calculations(self, df):
        """Verify indicator calculations are correct"""
        print("üîç === INDICATOR VERIFICATION ===")
        if len(df) > 0:
            last_row = df.iloc[-1]
            
            # Check EMA relationships
            ema_12 = last_row['ema_12']
            ema_26 = last_row['ema_26']
            ema_50 = last_row['ema_50']
            
            print(f"üìà EMA Values - 12: {ema_12:.2f}, 26: {ema_26:.2f}, 50: {ema_50:.2f}")
            
            # They should not all be equal
            if ema_12 == ema_26 == ema_50:
                print("‚ö†Ô∏è  WARNING: All EMAs have same value!")
            else:
                print("‚úÖ EMAs have different values - GOOD")
            
            # Check MACD consistency
            macd = last_row.get('macd', 0)
            macd_signal = last_row.get('macd_signal', 0)
            macd_hist = last_row.get('macd_hist', 0)
            expected_hist = macd - macd_signal
            
            print(f"üìä MACD - Value: {macd:.4f}, Signal: {macd_signal:.4f}, Hist: {macd_hist:.4f}")
            if abs(macd_hist - expected_hist) < 0.001:
                print("‚úÖ MACD histogram calculation - CORRECT")
            else:
                print(f"‚ùå MACD histogram calculation - ERROR: expected {expected_hist:.4f}")
            
            # Check other indicators
            for col in ['rsi', 'macd', 'stoch_k', 'stoch_d']:
                if col in df.columns:
                    value = last_row[col]
                    print(f"  {col}: {value:.2f}")
        
        # Check data variation
        for col in ['ema_12', 'ema_26', 'ema_50']:
            if col in df.columns:
                unique_count = df[col].nunique()
                print(f"  {col} unique values: {unique_count}/{len(df)}")
        
        print("=================================")

    def get_realtime_price_twelvedata(self):
        """Get real-time gold price from Twelve Data API"""
        try:
            if not self.twelve_data_api_key:
                print("‚ùå Twelve Data API key not set")
                return self.get_simulated_price()
            
            url = f"https://api.twelvedata.com/price?symbol=XAU/USD&apikey={self.twelve_data_api_key}"
            response = requests.get(url, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                if 'price' in data and data['price'] != '':
                    price = float(data['price'])
                    print(f"‚úÖ Real-time XAUUSD price from Twelve Data: ${price:.2f}")
                    return price
                else:
                    print(f"‚ùå Twelve Data API error: {data.get('message', 'No price data')}")
                    return self.get_simulated_price()
            else:
                print(f"‚ùå Twelve Data API HTTP error: {response.status_code}")
                return self.get_simulated_price()
                
        except Exception as e:
            print(f"‚ùå Error getting price from Twelve Data: {e}")
            return self.get_simulated_price()

    def get_simulated_price(self):
        """Fallback simulated price"""
        base_price = 4237.0
        movement = np.random.normal(0, 1.5)
        price = base_price + movement
        print(f"üîÑ Simulated XAUUSD price: ${price:.2f}")
        return round(price, 2)

    def get_realtime_price(self):
        """Main function to get real-time price"""
        return self.get_realtime_price_twelvedata()

    def get_fundamental_news(self):
        """Get fundamental news from NewsAPI - IMPROVED QUERY"""
        try:
            if not self.news_api_key:
                print("‚ùå NewsAPI key not set, using sample news")
                return self.get_sample_news()
            
            from_date = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d')  # Kurang hari
            
            # Improved query dengan multiple terms
            queries = [
                f"https://newsapi.org/v2/everything?q=gold+OR+XAUUSD+OR+precious+metals&from={from_date}&sortBy=popularity&language=en&apiKey={self.news_api_key}",
                f"https://newsapi.org/v2/everything?q=Federal+Reserve+OR+interest+rates+OR+inflation&from={from_date}&sortBy=popularity&language=en&apiKey={self.news_api_key}",
                f"https://newsapi.org/v2/top-headlines?category=business&country=us&apiKey={self.news_api_key}"
            ]
            
            all_articles = []
            
            for url in queries:
                try:
                    response = requests.get(url, timeout=10)
                    if response.status_code == 200:
                        data = response.json()
                        if data.get('status') == 'ok' and data.get('articles'):
                            all_articles.extend(data['articles'][:2])  # Ambil 2 artikel per query
                except Exception as e:
                    print(f"‚ö†Ô∏è NewsAPI query error: {e}")
                    continue
            
            if all_articles:
                # Remove duplicates berdasarkan title
                seen_titles = set()
                unique_articles = []
                for article in all_articles:
                    title = article.get('title', '')
                    if title and title not in seen_titles:
                        seen_titles.add(title)
                        unique_articles.append(article)
                
                print(f"‚úÖ Retrieved {len(unique_articles)} unique news articles")
                return {"articles": unique_articles[:3]}  # Maksimal 3 artikel
            
            print("‚ùå No articles found from NewsAPI, using sample news")
            return self.get_sample_news()
                
        except Exception as e:
            print(f"‚ùå Error getting news from NewsAPI: {e}")
            return self.get_sample_news()

    def get_sample_news(self):
        """Sample news data as fallback"""
        return {
            "articles": [
                {
                    "title": "Gold Prices Hold Steady Amid Economic Uncertainty",
                    "description": "XAUUSD maintains strong support levels as investors seek safe-haven assets.",
                    "publishedAt": datetime.now().isoformat(),
                    "source": {"name": "Financial Times"},
                    "url": "#"
                },
                {
                    "title": "Federal Reserve Policy Impacts Precious Metals",
                    "description": "Recent Fed announcements create favorable conditions for gold prices.",
                    "publishedAt": (datetime.now() - timedelta(hours=2)).isoformat(),
                    "source": {"name": "Bloomberg"},
                    "url": "#"
                }
            ]
        }

    def analyze_with_deepseek(self, technical_data, news_data):
        """Get AI analysis from DeepSeek API - ENHANCED VERSION"""
        try:
            current_time = time.time()
            if current_time - self.last_api_call < 10:
                print("‚è≥ Skipping DeepSeek API call (rate limiting)")
                return self.comprehensive_fallback_analysis(technical_data, news_data)
            
            if not self.deepseek_api_key:
                print("‚ùå DeepSeek API key not set, using comprehensive analysis")
                return self.comprehensive_fallback_analysis(technical_data, news_data)
            
            # Validasi API key format
            if not self.deepseek_api_key.startswith('sk-'):
                print("‚ùå DeepSeek API key format invalid, using fallback")
                return self.comprehensive_fallback_analysis(technical_data, news_data)
            
            current_price = technical_data.get('current_price', 0)
            indicators = technical_data.get('indicators', {})
            
            news_headlines = []
            if news_data and 'articles' in news_data:
                for article in news_data['articles'][:3]:
                    news_headlines.append(f"- {article['title']} ({article['source']['name']})")
            
            news_context = "\n".join(news_headlines) if news_headlines else "No significant news"
            
            prompt = f"""
Sebagai analis pasar keuangan profesional, berikan analisis komprehensif untuk XAUUSD (Gold/USD):

**DATA TEKNIKAL:**
- Harga Saat Ini: ${current_price:.2f}
- RSI (14): {indicators.get('rsi', 'N/A')}
- MACD: {indicators.get('macd', 'N/A')} | Signal: {indicators.get('macd_signal', 'N/A')}
- EMA 12: {indicators.get('ema_12', 'N/A')}
- EMA 26: {indicators.get('ema_26', 'N/A')}
- EMA 50: {indicators.get('ema_50', 'N/A')}
- Stochastic: K={indicators.get('stoch_k', 'N/A')}, D={indicators.get('stoch_d', 'N/A')}
- Bollinger Bands: Upper={indicators.get('bb_upper', 'N/A')}, Lower={indicators.get('bb_lower', 'N/A')}

**BERITA TERKINI:**
{news_context}

Berikan rekomendasi trading yang JELAS: BUY, SELL, atau HOLD dengan:
- Entry Price spesifik
- Stop Loss (SL) realistis  
- Minimal 2 level Take Profit (TP1, TP2) dengan risk-reward ratio minimal 1:2
- Risk-reward ratio harus disebutkan secara eksplisit

Format output profesional dengan:
1. EXECUTIVE SUMMARY
2. TECHNICAL ANALYSIS DETAILED
3. TRADING RECOMMENDATION dengan ENTRY, SL, TP1, TP2
4. RISK MANAGEMENT
5. FUNDAMENTAL CONTEXT
"""
            
            headers = {
                'Content-Type': 'application/json',
                'Authorization': f'Bearer {self.deepseek_api_key}'
            }
            
            data = {
                "model": "deepseek-chat",
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.7,
                "max_tokens": 1500,
                "stream": False
            }
            
            self.last_api_call = current_time
            
            # Enhanced timeout with retry and better error handling
            max_retries = 2
            timeout_duration = 30
            
            for attempt in range(max_retries):
                try:
                    print(f"ü§ñ Attempting DeepSeek API call (attempt {attempt + 1}/{max_retries})...")
                    
                    # Main API call
                    response = requests.post(
                        'https://api.deepseek.com/chat/completions',
                        headers=headers,
                        json=data,
                        timeout=timeout_duration
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        analysis = result['choices'][0]['message']['content']
                        print("‚úÖ DeepSeek AI analysis generated successfully")
                        return analysis
                    else:
                        print(f"‚ùå DeepSeek API error (attempt {attempt + 1}): {response.status_code}")
                        print(f"Response: {response.text}")
                        
                        if response.status_code == 401:
                            print("‚ùå Unauthorized - check API key")
                            return self.comprehensive_fallback_analysis(technical_data, news_data)
                        elif response.status_code == 429:
                            print("‚è≥ Rate limited, waiting...")
                            time.sleep(5)
                            continue
                        elif attempt == max_retries - 1:
                            return self.comprehensive_fallback_analysis(technical_data, news_data)
                            
                except requests.exceptions.Timeout:
                    print(f"‚è∞ DeepSeek API timeout (attempt {attempt + 1})")
                    if attempt == max_retries - 1:
                        return self.comprehensive_fallback_analysis(technical_data, news_data)
                        
                except requests.exceptions.ConnectionError as e:
                    print(f"üîå DeepSeek API connection error (attempt {attempt + 1}): {e}")
                    if attempt == max_retries - 1:
                        return self.comprehensive_fallback_analysis(technical_data, news_data)
                        
                except Exception as e:
                    print(f"‚ùå Unexpected error in DeepSeek API (attempt {attempt + 1}): {e}")
                    if attempt == max_retries - 1:
                        return self.comprehensive_fallback_analysis(technical_data, news_data)
                
                # Wait before retry
                if attempt < max_retries - 1:
                    time.sleep(3)
                    
            return self.comprehensive_fallback_analysis(technical_data, news_data)
            
        except Exception as e:
            print(f"‚ùå Critical error in DeepSeek analysis: {e}")
            return self.comprehensive_fallback_analysis(technical_data, news_data)

    def comprehensive_fallback_analysis(self, technical_data, news_data):
        """Comprehensive fallback analysis when AI fails"""
        current_price = technical_data.get('current_price', 0)
        indicators = technical_data.get('indicators', {})
        
        rsi = indicators.get('rsi', 50) or 50
        macd = indicators.get('macd', 0) or 0
        macd_signal = indicators.get('macd_signal', 0) or 0
        ema_12 = indicators.get('ema_12', current_price) or current_price
        ema_26 = indicators.get('ema_26', current_price) or current_price
        ema_50 = indicators.get('ema_50', current_price) or current_price
        
        bullish_signals = 0
        bearish_signals = 0
        
        if rsi < 30:
            bullish_signals += 2
            rsi_signal = "OVERSOLD - STRONG BUY"
        elif rsi < 40:
            bullish_signals += 1
            rsi_signal = "NEARLY OVERSOLD - BUY"
        elif rsi > 70:
            bearish_signals += 2
            rsi_signal = "OVERBOUGHT - STRONG SELL"
        elif rsi > 60:
            bearish_signals += 1
            rsi_signal = "NEARLY OVERBOUGHT - SELL"
        else:
            rsi_signal = "NEUTRAL"
        
        if macd > macd_signal:
            bullish_signals += 1
            macd_signal_text = "BULLISH CROSSOVER"
        else:
            bearish_signals += 1
            macd_signal_text = "BEARISH CROSSOVER"
        
        if current_price > ema_12 > ema_26 > ema_50:
            bullish_signals += 2
            ema_signal = "STRONG BULLISH TREND"
        elif current_price < ema_12 < ema_26 < ema_50:
            bearish_signals += 2
            ema_signal = "STRONG BEARISH TREND"
        elif current_price > ema_12 and ema_12 > ema_26:
            bullish_signals += 1
            ema_signal = "BULLISH TREND"
        elif current_price < ema_12 and ema_12 < ema_26:
            bearish_signals += 1
            ema_signal = "BEARISH TREND"
        else:
            ema_signal = "MIXED TREND"
        
        if bullish_signals - bearish_signals >= 3:
            trend = "STRONG BULLISH"
            signal = "BUY"
            risk = "MEDIUM"
            risk_reward = "1:3"
        elif bullish_signals - bearish_signals >= 1:
            trend = "BULLISH"
            signal = "BUY"
            risk = "MEDIUM"
            risk_reward = "1:2"
        elif bearish_signals - bullish_signals >= 3:
            trend = "STRONG BEARISH"
            signal = "SELL"
            risk = "HIGH"
            risk_reward = "1:3"
        elif bearish_signals - bullish_signals >= 1:
            trend = "BEARISH"
            signal = "SELL"
            risk = "MEDIUM"
            risk_reward = "1:2"
        else:
            trend = "NEUTRAL"
            signal = "HOLD/WAIT"
            risk = "LOW"
            risk_reward = "N/A"
        
        if signal == "BUY":
            entry = current_price
            stop_loss = entry * 0.99
            take_profit_1 = entry * 1.02
            take_profit_2 = entry * 1.03
            position_size = "Standard (1-2% risk per trade)"
        elif signal == "SELL":
            entry = current_price
            stop_loss = entry * 1.01
            take_profit_1 = entry * 0.98
            take_profit_2 = entry * 0.97
            position_size = "Standard (1-2% risk per trade)"
        else:
            entry = current_price
            stop_loss = entry * 0.995
            take_profit_1 = entry * 1.01
            take_profit_2 = entry * 1.02
            position_size = "Wait for clearer signal"
        
        analysis = f"""
**ANALISIS XAUUSD KOMPREHENSIF - TRADING RECOMMENDATION**
*Dibuat: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*

**EXECUTIVE SUMMARY:**
- Harga Saat Ini: ${current_price:.2f}
- Trend Pasar: {trend}
- **REKOMENDASI UTAMA: {signal}**
- Risk Level: {risk}
- Risk-Reward Ratio: {risk_reward}

**TECHNICAL ANALYSIS:**
- RSI (14): {rsi:.1f} - {rsi_signal}
- MACD: {macd:.4f} - {macd_signal_text}
- EMA Alignment: {ema_signal}

**TRADING RECOMMENDATION:**
**Action: {signal} XAUUSD**

**Entry Levels:**
- Ideal Entry: ${entry:.2f}

**Risk Management:**
- Stop Loss: ${stop_loss:.2f}
- Take Profit 1: ${take_profit_1:.2f} (Risk-Reward 1:2)
- Take Profit 2: ${take_profit_2:.2f} (Risk-Reward 1:3)
- Position Size: {position_size}

**TRADING PLAN:**
1. Entry pada ${entry:.2f}
2. Stop Loss: ${stop_loss:.2f}
3. Take Profit 1: ${take_profit_1:.2f} (50% position)
4. Take Profit 2: ${take_profit_2:.2f} (50% position)
5. Risk maksimal 2% dari equity per trade
"""
        return analysis

    def analyze_market_conditions(self, df, indicators, news_data):
        """Comprehensive market analysis using AI"""
        try:
            if len(df) == 0:
                return "No data available for analysis"
                
            current_price = df.iloc[-1]['close']
            
            technical_data = {
                'current_price': current_price,
                'indicators': indicators
            }
            
            analysis = self.analyze_with_deepseek(technical_data, news_data)
            return analysis
            
        except Exception as e:
            return f"Market analysis completed. Error in processing: {str(e)}"

# Create analyzer instance
analyzer = XAUUSDAnalyzer()

@app.route('/')
def home():
    """Serve main page"""
    try:
        return render_template('index.html')
    except Exception as e:
        return f"Error loading template: {str(e)}"

@app.route('/api/analysis/<timeframe>')
def get_analysis(timeframe):
    """Main analysis endpoint - ENHANCED VERSION"""
    try:
        print(f"üîç Processing analysis for {timeframe}")
        
        if timeframe not in ['1H', '4H', '1D']:
            return jsonify({"error": "Invalid timeframe"}), 400
        
        df = analyzer.load_historical_data(timeframe, 200)
        print(f"‚úÖ Loaded {len(df)} records for {timeframe}")
        
        df_with_indicators = analyzer.calculate_indicators(df)
        print("‚úÖ Indicators calculated")
        
        current_price = analyzer.get_realtime_price()
        print(f"üí∞ Current price: ${current_price:.2f}")
        
        if len(df_with_indicators) > 0:
            df_with_indicators.iloc[-1, df_with_indicators.columns.get_loc('close')] = current_price
            if current_price > df_with_indicators.iloc[-1]['high']:
                df_with_indicators.iloc[-1, df_with_indicators.columns.get_loc('high')] = current_price
            if current_price < df_with_indicators.iloc[-1]['low']:
                df_with_indicators.iloc[-1, df_with_indicators.columns.get_loc('low')] = current_price
        
        news_data = analyzer.get_fundamental_news()
        
        print("üìä Available columns in df_with_indicators:", df_with_indicators.columns.tolist())
        if len(df_with_indicators) > 0:
            last_row = df_with_indicators.iloc[-1]
            print("üîç Last row data sample:")
            for col in ['ema_12', 'ema_26', 'ema_50', 'rsi', 'macd', 'macd_signal', 'macd_hist', 'stoch_k', 'stoch_d', 'bb_upper', 'bb_lower']:
                if col in df_with_indicators.columns:
                    print(f"  {col}: {last_row[col]} (type: {type(last_row[col])})")
        
        latest_indicators = {}
        if len(df_with_indicators) > 0:
            last_row = df_with_indicators.iloc[-1]
            indicator_list = ['ema_12', 'ema_26', 'ema_50', 'rsi', 'macd', 'macd_signal', 'macd_hist', 
                             'stoch_k', 'stoch_d', 'bb_upper', 'bb_lower', 'bb_middle']
            
            for indicator in indicator_list:
                if indicator in df_with_indicators.columns:
                    value = last_row[indicator]
                    if value is not None and not pd.isna(value):
                        latest_indicators[indicator] = float(value)
                    else:
                        latest_indicators[indicator] = 0.0 if 'macd' in indicator else 50.0
                else:
                    latest_indicators[indicator] = 0.0 if 'macd' in indicator else 50.0
        
        print(f"‚úÖ Prepared {len(latest_indicators)} indicators for API response")
        
        analysis = analyzer.analyze_market_conditions(df_with_indicators, latest_indicators, news_data)
        
        chart_data = []
        display_data = df_with_indicators.tail(100)
        
        for _, row in display_data.iterrows():
            chart_point = {
                'datetime': row['datetime'].isoformat() if hasattr(row['datetime'], 'isoformat') else str(row['datetime']),
                'open': float(row['open']),
                'high': float(row['high']),
                'low': float(row['low']),
                'close': float(row['close']),
                'volume': float(row.get('volume', 0)),
            }
            
            indicator_columns = ['ema_12', 'ema_26', 'ema_50', 'macd', 'macd_signal', 'macd_hist', 
                               'rsi', 'bb_upper', 'bb_lower', 'bb_middle', 'stoch_k', 'stoch_d']
            
            for indicator in indicator_columns:
                if indicator in df_with_indicators.columns:
                    value = row[indicator]
                    if value is not None and not pd.isna(value):
                        chart_point[indicator] = float(value)
                    else:
                        chart_point[indicator] = 0.0 if 'macd' in indicator else 50.0
                else:
                    chart_point[indicator] = 0.0 if 'macd' in indicator else 50.0
            
            chart_data.append(chart_point)
        
        if chart_data:
            last_chart_point = chart_data[-1]
            print("üìà Last chart point indicators:")
            for key, value in last_chart_point.items():
                if key not in ['datetime', 'open', 'high', 'low', 'close', 'volume']:
                    print(f"  {key}: {value}")
        
        response = {
            "status": "success",
            "timestamp": datetime.now().isoformat(),
            "timeframe": timeframe,
            "current_price": current_price,
            "technical_indicators": latest_indicators,
            "ai_analysis": analysis,
            "chart_data": chart_data,
            "data_points": len(chart_data),
            "news": news_data,
            "api_sources": {
                "twelve_data": bool(analyzer.twelve_data_api_key),
                "deepseek": bool(analyzer.deepseek_api_key),
                "newsapi": bool(analyzer.news_api_key)
            }
        }
        
        print(f"‚úÖ Analysis completed for {timeframe}. Sent {len(chart_data)} data points with {len(latest_indicators)} indicators.")
        return jsonify(response)
        
    except Exception as e:
        print(f"‚ùå Error in analysis: {e}")
        traceback.print_exc()
        return jsonify({"error": str(e), "status": "error"}), 500

@app.route('/api/debug/indicators')
def debug_indicators():
    """Debug endpoint for indicator calculations"""
    try:
        timeframe = request.args.get('timeframe', '4H')
        df = analyzer.load_historical_data(timeframe, 200)
        df_with_indicators = analyzer.calculate_indicators(df)
        
        debug_info = {
            "timeframe": timeframe,
            "data_points": len(df_with_indicators),
            "price_range": {
                "min": float(df_with_indicators['close'].min()),
                "max": float(df_with_indicators['close'].max()),
                "current": float(df_with_indicators['close'].iloc[-1])
            },
            "last_calculations": {},
            "calculations_verified": analyzer.enhanced_indicator_verification(df_with_indicators),
            "data_quality": {
                "has_realistic_prices": analyzer.validate_price_data(df_with_indicators),
                "macd_consistent": True
            }
        }
        
        if len(df_with_indicators) > 0:
            last_row = df_with_indicators.iloc[-1]
            for col in ['ema_12', 'ema_26', 'ema_50', 'macd', 'macd_signal', 'macd_hist', 'rsi']:
                if col in df_with_indicators.columns:
                    debug_info["last_calculations"][col] = float(last_row[col])
            
            # Verify MACD consistency
            macd = last_row.get('macd', 0)
            macd_signal = last_row.get('macd_signal', 0)
            macd_hist = last_row.get('macd_hist', 0)
            expected_hist = macd - macd_signal
            debug_info["data_quality"]["macd_consistent"] = abs(macd_hist - expected_hist) < 0.001
        
        return jsonify(debug_info)
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/realtime/price')
def get_realtime_price():
    """Get real-time price only"""
    try:
        price = analyzer.get_realtime_price()
        return jsonify({
            "status": "success",
            "symbol": "XAUUSD",
            "price": price,
            "timestamp": datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/api/health')
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "twelve_data": bool(analyzer.twelve_data_api_key),
            "deepseek": bool(analyzer.deepseek_api_key),
            "newsapi": bool(analyzer.news_api_key),
            "talib": TALIB_AVAILABLE
        }
    })

@app.route('/api/debug')
def debug_info():
    """Debug information endpoint"""
    return jsonify({
        "status": "debug",
        "cache_size": len(analyzer.data_cache),
        "cached_timeframes": list(analyzer.data_cache.keys()),
        "last_api_call": analyzer.last_api_call,
        "environment_loaded": True
    })

if __name__ == '__main__':
    try:
        import dotenv
    except ImportError:
        print("üì¶ Installing python-dotenv...")
        os.system("pip install python-dotenv")
        from dotenv import load_dotenv
        load_dotenv()
    
    os.makedirs('data', exist_ok=True)
    os.makedirs('templates', exist_ok=True)
    
    print("=" * 70)
    print("üöÄ XAUUSD Professional Trading Analysis - ULTRA ENHANCED VERSION")
    print("=" * 70)
    print("üìä Available Endpoints:")
    print("  ‚Ä¢ GET / ‚Üí Dashboard")
    print("  ‚Ä¢ GET /api/analysis/1H ‚Üí 1Hour Analysis") 
    print("  ‚Ä¢ GET /api/analysis/4H ‚Üí 4Hour Analysis")
    print("  ‚Ä¢ GET /api/analysis/1D ‚Üí Daily Analysis")
    print("  ‚Ä¢ GET /api/debug/indicators ‚Üí Indicator Debug")
    print("  ‚Ä¢ GET /api/realtime/price ‚Üí Current Price")
    print("  ‚Ä¢ GET /api/health ‚Üí Health Check")
    print("  ‚Ä¢ GET /api/debug ‚Üí Debug Info")
    print("=" * 70)
    print("üîß Integrated APIs:")
    print("  ‚Ä¢ Twelve Data ‚Üí Real-time Prices")
    print("  ‚Ä¢ DeepSeek AI ‚Üí Market Analysis") 
    print("  ‚Ä¢ NewsAPI ‚Üí Fundamental News")
    print("=" * 70)
    print("üéØ CRITICAL FIXES IMPLEMENTED:")
    print("  ‚Ä¢ ‚úÖ AGGRESSIVE Data Cleaning - Removes unrealistic prices")
    print("  ‚Ä¢ ‚úÖ MACD Calculation FIX - Force histogram recalculation")
    print("  ‚Ä¢ ‚úÖ Enhanced DeepSeek API - Better error handling & retry")
    print("  ‚Ä¢ ‚úÖ Improved NewsAPI Queries - Multiple search terms")
    print("  ‚Ä¢ ‚úÖ Realistic Price Ranges - $1800-$4500 for gold")
    print("  ‚Ä¢ ‚úÖ Enhanced Validation - Comprehensive data checks")
    print("=" * 70)
    
    print("üöÄ Starting ultra-enhanced server...")
    app.run(debug=True, port=5000, host='0.0.0.0')
